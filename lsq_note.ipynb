{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 林绍钦 笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sever files sync with github\n",
    "\n",
    "[本文链接](InnoProject/lsq\\_note.ipynb)\n",
    "\n",
    "[创建版本库 - 廖雪峰的官方网站](https://www.liaoxuefeng.com/wiki/896043488029600/896827951938304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# On branch master\r\n",
      "# Changes not staged for commit:\r\n",
      "#   (use \"git add/rm <file>...\" to update what will be committed)\r\n",
      "#   (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "#   (commit or discard the untracked or modified content in submodules)\r\n",
      "#\r\n",
      "#\tdeleted:    lsq/.ipynb_checkpoints/README-checkpoint.ipynb\r\n",
      "#\tdeleted:    lsq/.ipynb_checkpoints/lsq_note-checkpoint.ipynb\r\n",
      "#\tdeleted:    lsq/README.ipynb\r\n",
      "#\tmodified:   lsq/TABOR (modified content, untracked content)\r\n",
      "#\tdeleted:    lsq/lsq_note.ipynb\r\n",
      "#\tdeleted:    lsq/lsq_note.md\r\n",
      "#\r\n",
      "# Untracked files:\r\n",
      "#   (use \"git add <file>...\" to include in what will be committed)\r\n",
      "#\r\n",
      "#\t.ipynb_checkpoints/\r\n",
      "#\tlsq_note.ipynb\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff --git a/lsq/.ipynb_checkpoints/README-checkpoint.ipynb b/lsq/.ipynb_checkpoints/README-checkpoint.ipynb\r\n",
      "deleted file mode 100644\r\n",
      "index 32de1ea..0000000\r\n",
      "--- a/lsq/.ipynb_checkpoints/README-checkpoint.ipynb\r\n",
      "+++ /dev/null\r\n",
      "@@ -1,416 +0,0 @@\r\n",
      "-{\r\n",
      "- \"cells\": [\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"markdown\",\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"source\": [\r\n",
      "-    \"# jupyter note sync with github\\n\",\r\n",
      "-    \"[用GitPython操作Git库 · 零壹軒·笔记](https://note.qidong.name/2018/01/gitpython/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## linux\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## server\\n\",\r\n",
      "-    \"\\n\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"markdown\",\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"source\": [\r\n",
      "-    \"# git\\n\",\r\n",
      "-    \"[创建版本库 - 廖雪峰的官方网站](https://www.liaoxuefeng.com/wiki/896043488029600/896827951938304)\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": 3,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [\r\n",
      "-    {\r\n",
      "-     \"name\": \"stdout\",\r\n",
      "-     \"output_type\": \"stream\",\r\n",
      "-     \"text\": [\r\n",
      "-      \"# On branch master\\r\\n\",\r\n",
      "-      \"#\\r\\n\",\r\n",
      "-      \"# Initial commit\\r\\n\",\r\n",
      "-      \"#\\r\\n\",\r\n",
      "-      \"# Untracked files:\\r\\n\",\r\n",
      "-      \"#   (use \\\"git add <file>...\\\" to include in what will be committed)\\r\\n\",\r\n",
      "-      \"#\\r\\n\",\r\n",
      "-      \"#\\t.ipynb_checkpoints/\\r\\n\",\r\n",
      "-      \"#\\tREADME.ipynb\\r\\n\",\r\n",
      "-      \"#\\tTABOR/\\r\\n\",\r\n",
      "-      \"#\\tdatabase_sqlite/\\r\\n\",\r\n",
      "-      \"#\\tlsq_note.ipynb\\r\\n\",\r\n",
      "-      \"#\\tlsq_note.md\\r\\n\",\r\n",
      "-      \"#\\tweb/\\r\\n\",\r\n",
      "-      \"nothing added to commit but untracked files present (use \\\"git add\\\" to track)\\r\\n\"\r\n",
      "-     ]\r\n",
      "-    }\r\n",
      "-   ],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!git status\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": 6,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [\r\n",
      "-    {\r\n",
      "-     \"name\": \"stdout\",\r\n",
      "-     \"output_type\": \"stream\",\r\n",
      "-     \"text\": [\r\n",
      "-      \"diff --git a/README.ipynb b/README.ipynb\\r\\n\",\r\n",
      "-      \"index e2b2f9a..64e5d8e 100644\\r\\n\",\r\n",
      "-      \"--- a/README.ipynb\\r\\n\",\r\n",
      "-      \"+++ b/README.ipynb\\r\\n\",\r\n",
      "-      \"@@ -22,29 +22,43 @@\\r\\n\",\r\n",
      "-      \"      \\\"name\\\": \\\"stdout\\\",\\r\\n\",\r\n",
      "-      \"      \\\"output_type\\\": \\\"stream\\\",\\r\\n\",\r\n",
      "-      \"      \\\"text\\\": [\\r\\n\",\r\n",
      "-      \"-      \\\"Collecting GitPython\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"  Using cached GitPython-3.1.0-py3-none-any.whl (450 kB)\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"Collecting gitdb<5,>=4.0.1\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"  Using cached gitdb-4.0.2-py3-none-any.whl (63 kB)\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"Collecting smmap<4,>=3.0.1\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"  Using cached smmap-3.0.1-py2.py3-none-any.whl (25 kB)\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"Installing collected packages: smmap, gitdb, GitPython\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"Successfully installed GitPython-3.1.0 gitdb-4.0.2 smmap-3.0.1\\\\n\\\"\\r\\n\",\r\n",
      "-      \"+      \\\"# On branch master\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"# Initial commit\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"# Untracked files:\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#   (use \\\\\\\"git add <file>...\\\\\\\" to include in what will be committed)\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\t.ipynb_checkpoints/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tREADME.ipynb\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tTABOR/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tdatabase_sqlite/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tlsq_note.ipynb\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tlsq_note.md\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tweb/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"nothing added to commit but untracked files present (use \\\\\\\"git add\\\\\\\" to track)\\\\r\\\\n\\\"\\r\\n\",\r\n",
      "-      \"      ]\\r\\n\",\r\n",
      "-      \"     }\\r\\n\",\r\n",
      "-      \"    ],\\r\\n\",\r\n",
      "-      \"    \\\"source\\\": [\\r\\n\",\r\n",
      "-      \"-    \\\"!pip install GitPython\\\"\\r\\n\",\r\n",
      "-      \"+    \\\"!git commit\\\"\\r\\n\",\r\n",
      "-      \"    ]\\r\\n\",\r\n",
      "-      \"   },\\r\\n\",\r\n",
      "-      \"   {\\r\\n\",\r\n",
      "-      \"    \\\"cell_type\\\": \\\"code\\\",\\r\\n\",\r\n",
      "-      \"    \\\"execution_count\\\": 2,\\r\\n\",\r\n",
      "-      \"    \\\"metadata\\\": {},\\r\\n\",\r\n",
      "-      \"-   \\\"outputs\\\": [],\\r\\n\",\r\n",
      "-      \"+   \\\"outputs\\\": [\\r\\n\",\r\n",
      "-      \"+    {\\r\\n\",\r\n",
      "-      \"+     \\\"name\\\": \\\"stdout\\\",\\r\\n\",\r\n",
      "-      \"+     \\\"output_type\\\": \\\"stream\\\",\\r\\n\",\r\n",
      "-      \"+     \\\"text\\\": [\\r\\n\",\r\n",
      "-      \"+      \\\"/root/innoproject/lsq\\\\r\\\\n\\\"\\r\\n\",\r\n",
      "-      \"+     ]\\r\\n\",\r\n",
      "-      \"+    }\\r\\n\",\r\n",
      "-      \"+   ],\\r\\n\",\r\n",
      "-      \"    \\\"source\\\": [\\r\\n\",\r\n",
      "-      \"-    \\\"import git\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-    \\\"new_repo = git.Repo.clone_from(url='https://github.com/Steven147/InnoProject.git', to_path='../github')\\\\n\\\"\\r\\n\",\r\n",
      "-      \"+    \\\"!pwd\\\"\\r\\n\",\r\n",
      "-      \"    ]\\r\\n\",\r\n",
      "-      \"   },\\r\\n\",\r\n",
      "-      \"   {\\r\\n\",\r\n",
      "-      \"@@ -53,21 +67,48 @@\\r\\n\",\r\n",
      "-      \"    \\\"metadata\\\": {},\\r\\n\",\r\n",
      "-      \"    \\\"outputs\\\": [\\r\\n\",\r\n",
      "-      \"     {\\r\\n\",\r\n",
      "-      \"-     \\\"data\\\": {\\r\\n\",\r\n",
      "-      \"-      \\\"text/plain\\\": [\\r\\n\",\r\n",
      "-      \"-       \\\"<git.Commit \\\\\\\"f95367ade7fc041a427e1e5068a301f302c16e19\\\\\\\">\\\"\\r\\n\",\r\n",
      "-      \"-      ]\\r\\n\",\r\n",
      "-      \"-     },\\r\\n\",\r\n",
      "-      \"-     \\\"execution_count\\\": 3,\\r\\n\",\r\n",
      "-      \"-     \\\"metadata\\\": {},\\r\\n\",\r\n",
      "-      \"-     \\\"output_type\\\": \\\"execute_result\\\"\\r\\n\",\r\n",
      "-      \"+     \\\"name\\\": \\\"stdout\\\",\\r\\n\",\r\n",
      "-      \"+     \\\"output_type\\\": \\\"stream\\\",\\r\\n\",\r\n",
      "-      \"+     \\\"text\\\": [\\r\\n\",\r\n",
      "-      \"+      \\\"# On branch master\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"# Initial commit\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"# Untracked files:\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#   (use \\\\\\\"git add <file>...\\\\\\\" to include in what will be committed)\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\t.ipynb_checkpoints/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tREADME.ipynb\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tTABOR/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tdatabase_sqlite/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tlsq_note.ipynb\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tlsq_note.md\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tweb/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"nothing added to commit but untracked files present (use \\\\\\\"git add\\\\\\\" to track)\\\\r\\\\n\\\"\\r\\n\",\r\n",
      "-      \"+     ]\\r\\n\",\r\n",
      "-      \"     }\\r\\n\",\r\n",
      "-      \"    ],\\r\\n\",\r\n",
      "-      \"    \\\"source\\\": [\\r\\n\",\r\n",
      "-      \"-    \\\"new_repo.index.commit('initialize')\\\"\\r\\n\",\r\n",
      "-      \"+    \\\"!git status\\\"\\r\\n\",\r\n",
      "-      \"    ]\\r\\n\",\r\n",
      "-      \"   },\\r\\n\",\r\n",
      "-      \"   {\\r\\n\",\r\n",
      "-      \"+   \\\"cell_type\\\": \\\"code\\\",\\r\\n\",\r\n",
      "-      \"+   \\\"execution_count\\\": 5,\\r\\n\",\r\n",
      "-      \"+   \\\"metadata\\\": {},\\r\\n\",\r\n",
      "-      \"+   \\\"outputs\\\": [],\\r\\n\",\r\n",
      "-      \"+   \\\"source\\\": [\\r\\n\",\r\n",
      "-      \"+    \\\"!git add .\\\"\\r\\n\",\r\n",
      "-      \"+   ]\\r\\n\",\r\n",
      "-      \"+  },\\r\\n\",\r\n",
      "-      \"+  {\\r\\n\",\r\n",
      "-      \"+   \\\"cell_type\\\": \\\"code\\\",\\r\\n\",\r\n",
      "-      \"+   \\\"execution_count\\\": null,\\r\\n\",\r\n",
      "-      \"+   \\\"metadata\\\": {},\\r\\n\",\r\n",
      "-      \"+   \\\"outputs\\\": [],\\r\\n\",\r\n",
      "-      \"+   \\\"source\\\": []\\r\\n\",\r\n",
      "-      \"+  },\\r\\n\",\r\n",
      "-      \"+  {\\r\\n\",\r\n",
      "-      \"    \\\"cell_type\\\": \\\"markdown\\\",\\r\\n\",\r\n",
      "-      \"    \\\"metadata\\\": {},\\r\\n\",\r\n",
      "-      \"    \\\"source\\\": [\\r\\n\",\r\n",
      "-      \"diff --git a/TABOR b/TABOR\\r\\n\",\r\n",
      "-      \"--- a/TABOR\\r\\n\",\r\n",
      "-      \"+++ b/TABOR\\r\\n\",\r\n",
      "-      \"@@ -1 +1 @@\\r\\n\",\r\n",
      "-      \"-Subproject commit 27b23895a3182d0f2d4c259b2f09ed1e859a94ad\\r\\n\",\r\n",
      "-      \"+Subproject commit 27b23895a3182d0f2d4c259b2f09ed1e859a94ad-dirty\\r\\n\"\r\n",
      "-     ]\r\n",
      "-    }\r\n",
      "-   ],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!git diff\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": 2,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [\r\n",
      "-    {\r\n",
      "-     \"name\": \"stdout\",\r\n",
      "-     \"output_type\": \"stream\",\r\n",
      "-     \"text\": [\r\n",
      "-      \"/root/innoproject/lsq\\r\\n\"\r\n",
      "-     ]\r\n",
      "-    }\r\n",
      "-   ],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!pwd\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": 5,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!git add .\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": 7,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [\r\n",
      "-    {\r\n",
      "-     \"name\": \"stdout\",\r\n",
      "-     \"output_type\": \"stream\",\r\n",
      "-     \"text\": [\r\n",
      "-      \"\\u001b7\\u001b[?47h\\u001b[?1h\\u001b=\\u001b[1;24r\\u001b[m\\u001b[H\\u001b[2J\\u001b[24;1H\\\".git/COMMIT_EDITMSG\\\" 51L, 2142C\\u001b[2;1H# Please enter the commit message for your changes. Lines starting\\n\",\r\n",
      "-      \"# with '#' will be ignored, and an empty message aborts the commit.\\n\",\r\n",
      "-      \"#\\n\",\r\n",
      "-      \"# Committer: root <root@localhost.localdomain>\\n\",\r\n",
      "-      \"#\\n\",\r\n",
      "-      \"# On branch master\\n\",\r\n",
      "-      \"#\\n\",\r\n",
      "-      \"# Initial commit\\n\",\r\n",
      "-      \"#\\n\",\r\n",
      "-      \"# Changes to be committed:\\n\",\r\n",
      "-      \"#   (use \\\"git rm --cached <file>...\\\" to unstage)\\n\",\r\n",
      "-      \"#\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   .ipynb_checkpoints/README-checkpoint.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   .ipynb_checkpoints/lsq_note-checkpoint.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   README.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   TABOR\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   database_sqlite/.ipynb_checkpoints/database_sqlite-checkpoinn\\u001b[19;1Ht.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   database_sqlite/.ipynb_checkpoints/search-checkpoint.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   database_sqlite/database_sqlite.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   database_sqlite/search.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   database_sqlite/test.db\\u001b[1;1H\\u001b[24;1HType  :quit<Enter>  to exit Vim\\u001b[24;32H\\u001b[K\\u0007\\u001b[1;1H\"\r\n",
      "-     ]\r\n",
      "-    }\r\n",
      "-   ],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!git commit\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": 9,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!git remote add origin git@github.com:Steven147/Innoproject.git\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": null,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [\r\n",
      "-    {\r\n",
      "-     \"name\": \"stdout\",\r\n",
      "-     \"output_type\": \"stream\",\r\n",
      "-     \"text\": [\r\n",
      "-      \"The authenticity of host 'github.com (13.250.177.223)' can't be established.\\r\\n\",\r\n",
      "-      \"RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.\\r\\n\",\r\n",
      "-      \"RSA key fingerprint is MD5:16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.\\r\\n\",\r\n",
      "-      \"Are you sure you want to continue connecting (yes/no)? \"\r\n",
      "-     ]\r\n",
      "-    }\r\n",
      "-   ],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!git push origin master\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": null,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [],\r\n",
      "-   \"source\": []\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"markdown\",\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"source\": [\r\n",
      "-    \"# 笔记 林绍钦\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[本文链接InnoProject/lsq\\\\_note.md](https://github.com/Steven147/InnoProject/blob/master/lsq/lsq_note.md)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 连接综述\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- termius\\n\",\r\n",
      "-    \"  - `sudo su -`\\n\",\r\n",
      "-    \"  - zft13917331612\\n\",\r\n",
      "-    \"  - `conda activate lsq_py36_tfgpu`\\n\",\r\n",
      "-    \"  - `jupyter notebook --no-browser --port=8889 --allow-root --certfile=mycert.pem --keyfile mykey.key`\\n\",\r\n",
      "-    \"- terminal\\n\",\r\n",
      "-    \"  - `ssh -N -f -L localhost:8888:localhost:8889 -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"  - zft13917331612\\n\",\r\n",
      "-    \"- [localhost](https://localhost:8888/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## SSH远程连接\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- Linux/MacOS 作为终端\\n\",\r\n",
      "-    \"  - IP地址:`202.120.39.26:10151`,账号密码:`ipp20aitrojan`,`zft13917331612`\\n\",\r\n",
      "-    \"  - 连接命令:`ssh -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"  - 输入密码:`zft13917331612`\\n\",\r\n",
      "-    \"  - 登入成功！:`[ipp20aitrojan@localhost ~]$ .....`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 终端软件：[Introduction - Termius Documentation](https://docs.termius.com/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## jupyter notebook 远程连接\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[远程访问服务器Jupyter Notebook的两种方法 - 简书](https://www.jianshu.com/p/8fc3cd032d3c)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Running a notebook server — Jupyter Notebook 7.0.0.dev0 documentation](https://jupyter-notebook.readthedocs.io/en/latest/public_server.html#notebook-server-security)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 打开终端1：将本地端口号8888映射到服务器8889该过程只需要执行一次(通过`killall ssh`可以取消执行)\\n\",\r\n",
      "-    \"  - `ssh -N -f -L localhost:8888:localhost:8889 -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"  - 输入密码:`zft13917331612`\\n\",\r\n",
      "-    \"- 打开终端2\\n\",\r\n",
      "-    \"  - 使用SSH连接\\n\",\r\n",
      "-    \"    - 连接命令:`ssh -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"    - 输入密码:`zft13917331612`\\n\",\r\n",
      "-    \"  - 新建conda环境（python3），在新环境里下载jupyter notebook：`pip install notebook`\\n\",\r\n",
      "-    \"  - 配置jupyter环境（省略，因为已经配好了）\\n\",\r\n",
      "-    \"  - `jupyter notebook --no-browser --port=8889 --allow-root --certfile=mycert.pem --keyfile mykey.key`\\n\",\r\n",
      "-    \"- 用网页打开链接[localhost](https://localhost:8888/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## Linux 基本使用\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [27个常用的 Linux 命令 - 简书](https://www.jianshu.com/p/0056d671ea6d)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [Ranger 用法总结 | 盼 の 欲](http://www.huangpan.net/posts/ji-ke/2019-08-21-ranger.html)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- `sudo su -`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## tf环境搭建\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"### 0 资源链接\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Anaconda Python/R Distribution - Free Download](https://www.anaconda.com/distribution/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Install TensorFlow 2](https://tensorflow.google.cn/install)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[tensorflow-tutorials](https://tensorflow.google.cn/tutorials)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"### 1 pip安装tf-gpu流程\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [Anaconda Python/R Distribution - Free Download](https://www.anaconda.com/distribution/)\\n\",\r\n",
      "-    \"  - Windows 下载安装包进行安装（过程略\\n\",\r\n",
      "-    \"  - Linux:\\n\",\r\n",
      "-    \"    - `$ wget https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh`\\n\",\r\n",
      "-    \"    - 运行shell\\n\",\r\n",
      "-    \"    - 将anaconda的bin目录加入PATH:`$ echo 'export PATH=\\\"~/anaconda3/bin:$PATH\\\"' >> ~/.bashrc`\\n\",\r\n",
      "-    \"    - 更新bashrc以立即生效:`$ source ~/.bashrc`\\n\",\r\n",
      "-    \"  - 检验:`conda --version`\\n\",\r\n",
      "-    \"  - [Conda常用命令整理\\\\_运维\\\\_Working. Playing.-CSDN博客](https://blog.csdn.net/menc15/article/details/71477949)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- （已经安装好了现成环境py36_tfgpu，拷贝为lsq_py36_tfgpu）`conda create --name lsq_py36_tfgpu --clone py36_tfgpu`\\n\",\r\n",
      "-    \"- `conda activate lsq_py36_tfgpu`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [Install TensorFlow 2](https://tensorflow.google.cn/install)\\n\",\r\n",
      "-    \"  - 检验安装\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"    ```py\\n\",\r\n",
      "-    \"    import tensorflow as tf\\n\",\r\n",
      "-    \"    tf.test.is_gpu_available()\\n\",\r\n",
      "-    \"    ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"### 2 错误处理\\n\",\r\n",
      "-    \"\\n\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": null,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [],\r\n",
      "-   \"source\": []\r\n",
      "-  }\r\n",
      "- ],\r\n",
      "- \"metadata\": {\r\n",
      "-  \"kernelspec\": {\r\n",
      "-   \"display_name\": \"Python 3\",\r\n",
      "-   \"language\": \"python\",\r\n",
      "-   \"name\": \"python3\"\r\n",
      "-  },\r\n",
      "-  \"language_info\": {\r\n",
      "-   \"codemirror_mode\": {\r\n",
      "-    \"name\": \"ipython\",\r\n",
      "-    \"version\": 3\r\n",
      "-   },\r\n",
      "-   \"file_extension\": \".py\",\r\n",
      "-   \"mimetype\": \"text/x-python\",\r\n",
      "-   \"name\": \"python\",\r\n",
      "-   \"nbconvert_exporter\": \"python\",\r\n",
      "-   \"pygments_lexer\": \"ipython3\",\r\n",
      "-   \"version\": \"3.6.10\"\r\n",
      "-  }\r\n",
      "- },\r\n",
      "- \"nbformat\": 4,\r\n",
      "- \"nbformat_minor\": 4\r\n",
      "-}\r\n",
      "diff --git a/lsq/.ipynb_checkpoints/lsq_note-checkpoint.ipynb b/lsq/.ipynb_checkpoints/lsq_note-checkpoint.ipynb\r\n",
      "deleted file mode 100644\r\n",
      "index ba4786a..0000000\r\n",
      "--- a/lsq/.ipynb_checkpoints/lsq_note-checkpoint.ipynb\r\n",
      "+++ /dev/null\r\n",
      "@@ -1,853 +0,0 @@\r\n",
      "-{\r\n",
      "- \"cells\": [\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"markdown\",\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"source\": [\r\n",
      "-    \"# 笔记 林绍钦\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[本文链接InnoProject/lsq\\\\_note.md](https://github.com/Steven147/InnoProject/blob/master/lsq/lsq_note.md)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## SSH远程连接\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- Linux/MacOS 作为终端\\n\",\r\n",
      "-    \"  - IP地址:`202.120.39.26:10151`,账号密码:`ipp20aitrojan`,`zft13917331612`\\n\",\r\n",
      "-    \"  - 连接命令:`ssh -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"  - 输入密码:`zft13917331612`\\n\",\r\n",
      "-    \"  - 登入成功！:`[ipp20aitrojan@localhost ~]$ .....`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 终端软件：[Introduction - Termius Documentation](https://docs.termius.com/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## jupyter notebook 远程连接\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[远程访问服务器Jupyter Notebook的两种方法 - 简书](https://www.jianshu.com/p/8fc3cd032d3c)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Running a notebook server — Jupyter Notebook 7.0.0.dev0 documentation](https://jupyter-notebook.readthedocs.io/en/latest/public_server.html#notebook-server-security)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 打开终端1：将本地端口号8888映射到服务器8889该过程只需要执行一次(通过`killall ssh`可以取消执行)\\n\",\r\n",
      "-    \"  - `ssh -N -f -L localhost:8888:localhost:8889 -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"  - 输入密码:`zft13917331612`\\n\",\r\n",
      "-    \"- 打开终端2\\n\",\r\n",
      "-    \"  - 使用SSH连接\\n\",\r\n",
      "-    \"    - 连接命令:`ssh -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"    - 输入密码:`zft13917331612`\\n\",\r\n",
      "-    \"  - 新建conda环境（python3），在新环境里下载jupyter notebook：`pip install notebook`\\n\",\r\n",
      "-    \"  - 配置jupyter环境（省略，因为已经配好了）\\n\",\r\n",
      "-    \"  - `jupyter notebook --no-browser --port=8889 --allow-root --certfile=mycert.pem --keyfile mykey.key`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 用网页打开链接[localhost](https://localhost:8888/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## Linux 基本使用\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [27个常用的 Linux 命令 - 简书](https://www.jianshu.com/p/0056d671ea6d)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [Ranger 用法总结 | 盼 の 欲](http://www.huangpan.net/posts/ji-ke/2019-08-21-ranger.html)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- `sudo su -`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## tf环境搭建\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"### 0 资源链接\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Anaconda Python/R Distribution - Free Download](https://www.anaconda.com/distribution/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Install TensorFlow 2](https://tensorflow.google.cn/install)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[tensorflow-tutorials](https://tensorflow.google.cn/tutorials)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"### 1 pip安装tf-gpu流程\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [Anaconda Python/R Distribution - Free Download](https://www.anaconda.com/distribution/)\\n\",\r\n",
      "-    \"  - Windows 下载安装包进行安装（过程略\\n\",\r\n",
      "-    \"  - Linux:\\n\",\r\n",
      "-    \"    - `$ wget https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh`\\n\",\r\n",
      "-    \"    - 运行shell\\n\",\r\n",
      "-    \"    - 将anaconda的bin目录加入PATH:`$ echo 'export PATH=\\\"~/anaconda3/bin:$PATH\\\"' >> ~/.bashrc`\\n\",\r\n",
      "-    \"    - 更新bashrc以立即生效:`$ source ~/.bashrc`\\n\",\r\n",
      "-    \"  - 检验:`conda --version`\\n\",\r\n",
      "-    \"  - [Conda常用命令整理\\\\_运维\\\\_Working. Playing.-CSDN博客](https://blog.csdn.net/menc15/article/details/71477949)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- （已经安装好了现成环境py36_tfgpu，拷贝为lsq_py36_tfgpu）`conda create --name lsq_py36_tfgpu --clone py36_tfgpu`\\n\",\r\n",
      "-    \"- `conda activate lsq_py36_tfgpu`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [Install TensorFlow 2](https://tensorflow.google.cn/install)\\n\",\r\n",
      "-    \"  - 检验安装\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"    ```py\\n\",\r\n",
      "-    \"    import tensorflow as tf\\n\",\r\n",
      "-    \"    tf.test.is_gpu_available()\\n\",\r\n",
      "-    \"    ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"### 2 错误处理\\n\",\r\n",
      "-    \"\\n\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"markdown\",\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"source\": [\r\n",
      "-    \"# CITtrip项目：基于深度学习的网络异常行为检测\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"> 2.1 更新：《深度学习概览：算法，技术和应用》论文学习\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.2 更新：吴恩达-深度学习-bilibili\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.18 更新：《网络异常检测技术概述》论文学习 + tensorflow_keras学习\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.19 更新：《生成式对抗网络GAN的研究进展与展望_王坤峰》论文学习 + GAN模型损失函数理解 + tensorflow_keras学习2\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.20 更新：《基于深度卷积神经网络的网络流量分类方法》《卷积神经网络研究综述_周飞燕》论文学习 + tensorflow_keras学习3\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.21 更新：基于 tensorflow keras 的卷积神经网络实现 + tensorflow_gpu_for_mac install\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.22 更新：《基于深度置信网络的入侵检测模型》论文学习 + tensorflow keras 学习\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.23 更新：tensorflow keras\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.25 更新：《基于深度学习的网络流量分类及异常检测方法研究_王伟》 + 网络流量dataset组成 学习\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.26 更新：反向传播算法bp理解\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.29 更新：tensorflow keras 学习\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 3.6 更新：本地程序运行 用tf.keras实现GAN网络\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 信息安全竞赛安排\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料一: 基于深度学习的网络异常检测技术研究_尹传龙\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 绪论\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   - 异常行为检测概述\\n\",\r\n",
      "-    \"     - 网络异常：网络设备异常、网络安全异常\\n\",\r\n",
      "-    \"     - 异常检测：设定正常行为轮廓“阈值”\\n\",\r\n",
      "-    \"       - 入侵检测：违背既定安全策略\\n\",\r\n",
      "-    \"       - 僵尸网络检测：受感染计算机构成的网络\\n\",\r\n",
      "-    \"   - 研究现状\\n\",\r\n",
      "-    \"     - 统计分析、数据挖掘、特征工程、\\n\",\r\n",
      "-    \"     - 机器学习\\n\",\r\n",
      "-    \"       - 贝叶斯网络\\n\",\r\n",
      "-    \"       - 遗传算法：模拟选择、交叉、变异等操作的搜索方法\\n\",\r\n",
      "-    \"       - 支持向量机：寻找最佳超平面区分不同类的样本\\n\",\r\n",
      "-    \"       - k最近邻\\n\",\r\n",
      "-    \"       - 决策树\\n\",\r\n",
      "-    \"       - 模糊逻辑\\n\",\r\n",
      "-    \"       - 人工神经网络\\n\",\r\n",
      "-    \"       - 深度学习\\n\",\r\n",
      "-    \"   - 数据集\\n\",\r\n",
      "-    \"     - 检测方法在实际中的检测性能效果高度依赖数据集\\n\",\r\n",
      "-    \"  \\n\",\r\n",
      "-    \"2. 全连接循环神经网络的入侵检测技术(略)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"3. 生成式对抗网络的入侵检测技术\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   - 生成式对抗网络：目的是学习真实数据样本的概率分布\\n\",\r\n",
      "-    \"     - 深度生成模型、引入对抗思想，解决样本较少问题\\n\",\r\n",
      "-    \"     - 由生成模型和判别模型组成\\n\",\r\n",
      "-    \"       - 生成模型为了尽可能模仿真实样本，学习捕捉真实数据样本的概率分布\\n\",\r\n",
      "-    \"       - 判别模型对真实样本和生成样本分类，等价于二分类模型\\n\",\r\n",
      "-    \"       - 双方对抗、优化，达到纳什平衡：生成\\n\",\r\n",
      "-    \"     - 问题：基于极大极小博弈机制的优化问题\\n\",\r\n",
      "-    \"       - 一方面：进化判别模型D，提升判别准确率\\n\",\r\n",
      "-    \"         - D(x) 将真实样本x判断为真实样本的概率，正确判断\\n\",\r\n",
      "-    \"         - D(G(z)) 将生成样本判断为真实样本的概率，错误判断\\n\",\r\n",
      "-    \"         - 目的：改善D，使D(x)增大、D(G(z))减小\\n\",\r\n",
      "-    \"       - 另一方面：进化生成模型G，尽量生成与真实数据相似的样本\\n\",\r\n",
      "-    \"         - G(z) 噪声z到生成样本空间的映射\\n\",\r\n",
      "-    \"         - 目的：改善G，使D(G(z))增大\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料二: A Survey on Deep Learning: Algorithms, Techniques, and Applications 深度学习概览：算法，技术和应用\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"> Deep learning uses multiple layers to represent the abstractions of data to build computational models.\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> The lack of core understanding renders these powerful methods as black-box machines that inhibit development at a fundamental level.\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> Moreover, deep learning has repeatedly been perceived as a silver bullet to all stumbling blocks in machine learning, which is far from the truth.\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- INTRODUCTION\\n\",\r\n",
      "-    \"  - 应用：多媒体概念检索，图像分类，视频推荐，社交网络分析，文本挖掘，**自然语言处理（NLP）**，视觉数据处理，语音和音频处理\\n\",\r\n",
      "-    \"  \\n\",\r\n",
      "-    \"    Deep learning, which has its roots from conventional neural networks, significantly outperforms its predecessors. It utilizes graph technologies with transformations among neurons to develop many-layered learning models.\\n\",\r\n",
      "-    \"    深度学习起源于传统的神经网络，其性能明显优于其前辈。它利用图技术以及神经元之间的转换来开发多层学习模型。\\n\",\r\n",
      "-    \"  - feature engineering 传统上，不良的数据表示通常会导致性能降低，因此，特征工程一直是重要的，且局限在特定领域，需要大量的人力\\n\",\r\n",
      "-    \"  - 相比之下，深度学习算法以自动方式执行特征提取，\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"    These algorithms include a layered architecture of data representation, where the high-level features can be extracted from the last layers of the networks while the  low-level features are extracted from the lower layers这些算法包括分层的数据表示架构，高层特征可以从网络的最后一层中提取，而底层要素从较低层提取\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"    The input is the scene information received from eyes, while the output is the classified objects.我们的大脑可以自动从不同场景中提取数据表示。 输入是从眼睛接收场景信息，而输出是分类对象。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"  - History\\n\",\r\n",
      "-    \"    - In 1980, neocogitron was intrduced, which inspired the convolutional neural network\\n\",\r\n",
      "-    \"    - Recurrent Neutal Networks were proposed in 1986\\n\",\r\n",
      "-    \"    - LeNet made the Deep Neural Networks\\n\",\r\n",
      "-    \"    - Deep Belief Networks (DBNs):Its main idea was to train a simple two-layer unsupervised model like Restricted Boltzmann Machines (RBMs), freeze all the parameters, stick a new layer on top, and train just the parameters for the new layer. 它的主要思想是训练一个简单的两层无监督模型，例如Restricted玻尔兹曼机器（RBM），冻结所有参数，在顶部粘贴新层并仅训练新层的参数。\\n\",\r\n",
      "-    \"    - deep learning now is one of the most efficient tools compared to other machinelearning algorithms with great performanc.与其他机器学习相比，深度学习现在是最有效的工具之一\\n\",\r\n",
      "-    \"    - ***从最初的Artificial Neural Networks(ANN)，到Deep Belief Networks DBN，Restricted Boltzmann Machines (RBMs)，Recurrent Neural Networks (RNNs)和Convolutional Neural Networks（CNN）***\\n\",\r\n",
      "-    \"    - 由于大量数据没有标签或带有噪音标签，因此一些研究更多地侧重于使用**无监督或半监督的**深度学习技术来提高训练模块的噪声鲁棒性。\\n\",\r\n",
      "-    \"    - cross-modality structure：由于当前大多数深度学习模型仅关注单一模式，因此导致对真实数据的表示有限。 研究人员现在更加关注跨模式结构\\n\",\r\n",
      "-    \"    - **Google AlphaGo**\\n\",\r\n",
      "-    \"  - Research Objectives and Outline 研究目的和概述\\n\",\r\n",
      "-    \"    - 介绍顶级论文，作者的经验，以及在深度神经网络研究和应用中的突破。\\n\",\r\n",
      "-    \"    - 在我们的调查中，提出了深度学习关键领域中的挑战和机遇，包括并行性，可伸缩性，功能和优化。为了解决上述问题，在不同的领域中引入了不同种类的深度网络，例如用于NLP的RNN和用于图像处理的CNN。 本文还介绍并比较了流行的深度学习工具，包括**Caffe，DeepLearning4j，TensorFlow，Theano和Torch**，以及每种深度学习工具中的优化技术。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- DEEP LEARNING NETWORKS：在第2节中，简要介绍了流行的深度学习网络。\\n\",\r\n",
      "-    \"  - 本节介绍的深度学习网络与其要点\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      | DL Networks | Descriptive Key Points                            |\\n\",\r\n",
      "-    \"      | ----------- | ------------------------------------------------- |\\n\",\r\n",
      "-    \"      | RvNN        | 使用树状结构。 NLP的首选                          |\\n\",\r\n",
      "-    \"      | RNN         | 适合顺序信息。首选用于NLP和语音处理               |\\n\",\r\n",
      "-    \"      | CNN         | 最初用于图像识别，扩展到NLP，语音处理和计算机视觉 |\\n\",\r\n",
      "-    \"      | DBN         | 无监督学习。定向连接                              |\\n\",\r\n",
      "-    \"      | DBM         | 无监督学习。RBM的复合模型。无向连接               |\\n\",\r\n",
      "-    \"      | GAN         | 无监督学习。博弈论框架                            |\\n\",\r\n",
      "-    \"      | VAE         | 无监督学习。概率图形模型                          |\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"  - Recursive Neural Network (RvNN)\\n\",\r\n",
      "-    \"  - Recurrent Neural Network (RNN)\\n\",\r\n",
      "-    \"  - Convolutional Neural Network (CNN)\\n\",\r\n",
      "-    \"  - Deep Generative Networks\\n\",\r\n",
      "-    \"- DEEP LEARNING TECHNIQUES AND FRAMEWORKS：第三部分讨论了深度学习中的几种算法，技术和框架。\\n\",\r\n",
      "-    \"  - Unsupervised and Transfer Learning 无监督和转移学习\\n\",\r\n",
      "-    \"  - Online Learning\\n\",\r\n",
      "-    \"  - Optimization Techniques in Deep Learning 深度学习中的优化技术\\n\",\r\n",
      "-    \"  - Deep Learning in Distributed Systems\\n\",\r\n",
      "-    \"  - Deep Lear ning Frameworks\\n\",\r\n",
      "-    \"- VARIOUS APPLICATIONS OF DEEP LEARNING：第4节中提供了许多深度学习的应用。\\n\",\r\n",
      "-    \"  - Natural Language Processing（略）\\n\",\r\n",
      "-    \"  - Visual Data Processing（略）\\n\",\r\n",
      "-    \"  - Speech and Audio Processing（略）\\n\",\r\n",
      "-    \"  - Other Applications（略）\\n\",\r\n",
      "-    \"- DEEP LEARNING CHALLENGES AND FUTURE DIRECTIONS：第5节指出了未来的挑战和潜在的研究方向。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料三：A survey of network anomaly detection techniques 网络异常检测技术概述\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 介绍\\n\",\r\n",
      "-    \"   1. 异常检测：数据挖掘任务 又称 utlier detection, novelty detection，deviation detection and exception mining.\\n\",\r\n",
      "-    \"   2. 异常：一个`与众不同`、疑似是`由不同的机制所产生`的观察结果\\n\",\r\n",
      "-    \"   3. 研究的挑战：异常检测技术普适性差（有线网-无线网）、噪声、缺乏labeled dataset\\n\",\r\n",
      "-    \"   4. 标准：计算复杂度、攻击检测优先级、输出\\n\",\r\n",
      "-    \"2. 前言\\n\",\r\n",
      "-    \"   1. 异常类型\\n\",\r\n",
      "-    \"      1. 点异常：\\n\",\r\n",
      "-    \"      2. 上下文异常：圣诞节交通量高在上下文中是正常的\\n\",\r\n",
      "-    \"      3. 集体异常：低心电图\\n\",\r\n",
      "-    \"   2. 异常检测技术的输出\\n\",\r\n",
      "-    \"      1. score\\n\",\r\n",
      "-    \"      2. label\\n\",\r\n",
      "-    \"   3. 网络攻击的类型\\n\",\r\n",
      "-    \"      1. 拒绝服务DoS攻击：server is flooded with numerous connection requests.\\n\",\r\n",
      "-    \"      2. 探针：探查攻击，对主机和网络攻击的第一步\\n\",\r\n",
      "-    \"      3. 用户到根U2R：获取super账户访问权限\\n\",\r\n",
      "-    \"      4. 远程用户R2U：\\n\",\r\n",
      "-    \"   4. 对异常的网络攻击进行分类  \\n\",\r\n",
      "-    \"      1. DoS：集体异常  \\n\",\r\n",
      "-    \"      2. 探测攻击：上下文异常\\n\",\r\n",
      "-    \"      3. 用户到根U2R，远程用户R2U：点异常\\n\",\r\n",
      "-    \"3. 基于分类的网络异常检测\\n\",\r\n",
      "-    \"   1. 支持向量机\\n\",\r\n",
      "-    \"      1. 寻找最优超平面，最大化分离\\n\",\r\n",
      "-    \"      2. `监督学习`！，\\n\",\r\n",
      "-    \"      3. 实例：正常活动下，有一组注册表项会被访问\\n\",\r\n",
      "-    \"   2. 贝叶斯网络\\n\",\r\n",
      "-    \"   3. 神经网络\\n\",\r\n",
      "-    \"   4. 基于规则：学习系统的正常行为\\n\",\r\n",
      "-    \"4. 统计异常检测\\n\",\r\n",
      "-    \"   1. 混合模型：数据由两个分布M，A其中一个生成，由A生成则是异常数据\\n\",\r\n",
      "-    \"   2. 信号处理技术\\n\",\r\n",
      "-    \"   3. 主成分分析：无假设、降维且不损失重要信息\\n\",\r\n",
      "-    \"5. 信息理论\\n\",\r\n",
      "-    \"   1. 信息熵、条件熵、相对熵\\n\",\r\n",
      "-    \"   2. 相关分析：网络流量间的非线性相关性\\n\",\r\n",
      "-    \"6. 聚类：无监督！\\n\",\r\n",
      "-    \"   1. 常规聚类：k-means聚类算法，分为正常，异常两类\\n\",\r\n",
      "-    \"7. 入侵检测数据集：\\n\",\r\n",
      "-    \"   1. DARPA / KDD数据集\\n\",\r\n",
      "-    \"   2. 当代网络攻击评估数据集：ADFA-LD12\\n\",\r\n",
      "-    \"8. 评估\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料四：生成式对抗网络GAN的研究进展与展望_王坤峰\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. GAN提出背景\\n\",\r\n",
      "-    \"   1. 生成式模型：通过生成方法（对数据分布的学习）得到的模型\\n\",\r\n",
      "-    \"      1. `人类理解数据角度`：对数据进行分布/参数假设-用真实数据进行训练/拟合-用学习到的分布/模型生成新样本：\\n\",\r\n",
      "-    \"         1. 最大似然估计\\n\",\r\n",
      "-    \"         2. **马尔科夫链**：效率较低\\n\",\r\n",
      "-    \"      2. `机器理解数据角度`：模型不直接拟合，而是从未明确假设的分布（初始数据集）中获取数据，对模型进行修正\\n\",\r\n",
      "-    \"   2. 神经网络：解决参数多、训练难的问题；\\n\",\r\n",
      "-    \"      1. 训练：反向传播算法\\n\",\r\n",
      "-    \"      2. 结构：自由灵活\\n\",\r\n",
      "-    \"      3. 建模能力：理论上能够逼近任意函数\\n\",\r\n",
      "-    \"   3. 对抗思想：AlphaGo 两个网络博弈\\n\",\r\n",
      "-    \"2. GAN的理论与实现模型\\n\",\r\n",
      "-    \"   1. 基本原理\\n\",\r\n",
      "-    \"      1. 生成器：学习真实的数据分布\\n\",\r\n",
      "-    \"         - G(z) 噪声z到生成样本空间的映射\\n\",\r\n",
      "-    \"         - 目的：改善G，使D(G(z))增大\\n\",\r\n",
      "-    \"      2. 判别器：判别数据是否源于生成器\\n\",\r\n",
      "-    \"         1. 判断是真实数据, 标记为 1（和D的取值不同！！\\n\",\r\n",
      "-    \"         2. 判断是生成器数据，标记为 0（和D的取值不同！！\\n\",\r\n",
      "-    \"         - D(x) 将真实样本x判断为真实样本的概率，正确判断\\n\",\r\n",
      "-    \"         - D(G(z)) 将生成样本判断为真实样本的概率，错误判断\\n\",\r\n",
      "-    \"         - 目的：改善D，使D(x)增大、D(G(z))减小\\n\",\r\n",
      "-    \"   2. `学习方法！！`：\\n\",\r\n",
      "-    \"      1. 最优化判别器：损失函数：对照图像理解\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"          > logistic回归 损失函数\\n\",\r\n",
      "-    \"          >\\n\",\r\n",
      "-    \"          > $J\\\\left( \\\\theta  \\\\right)=\\\\frac{1}{m}\\\\sum\\\\limits_{i=1}^{m}{{Cost}\\\\left( {h_\\\\theta}\\\\left( {x}^{\\\\left( i \\\\right)} \\\\right),{y}^{\\\\left( i \\\\right)} \\\\right)}$\\n\",\r\n",
      "-    \"          >\\n\",\r\n",
      "-    \"          > 为得到凸函数$J\\\\left( \\\\theta  \\\\right)$\\n\",\r\n",
      "-    \"          >\\n\",\r\n",
      "-    \"          > $J\\\\left( \\\\theta  \\\\right)=\\\\frac{1}{m}\\\\sum\\\\limits_{i=1}^{m}{[-{{y}^{(i)}}\\\\log \\\\left( {h_\\\\theta}\\\\left( {{x}^{(i)}} \\\\right) \\\\right)-\\\\left( 1-{{y}^{(i)}} \\\\right)\\\\log \\\\left( 1-{h_\\\\theta}\\\\left( {{x}^{(i)}} \\\\right) \\\\right)]}$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         - 训练判别器的损失函数：自变量有两个来源\\n\",\r\n",
      "-    \"           - ${D_\\\\theta}\\\\left( {x}\\\\right)$ 正确判断概率，目标为1，损失即与1的距离：$\\\\log \\\\left( {D_\\\\theta}\\\\left( {x} \\\\right) \\\\right)$\\n\",\r\n",
      "-    \"           - ${D_\\\\theta}\\\\left( g\\\\left(z \\\\right)\\\\right)$ 错误判断概率，目标为0，损失即与0的距离：$\\\\log \\\\left(1- {D_\\\\theta}\\\\left( {z} \\\\right) \\\\right)$\\n\",\r\n",
      "-    \"         - $J\\\\left( \\\\theta_D \\\\right)=-\\\\frac{1}{2}{E_1}\\\\log \\\\left( {D_\\\\theta}\\\\left( {x} \\\\right) \\\\right)- \\\\frac{1}{2}E_2 \\\\log \\\\left( 1-{D_\\\\theta }\\\\left( G\\\\left(z \\\\right)\\\\right) \\\\right)$\\n\",\r\n",
      "-    \"  \\n\",\r\n",
      "-    \"      2. 最优化生成器：损失函数，取判别器损失函数的相反数\\n\",\r\n",
      "-    \"         - $J\\\\left( \\\\theta_G \\\\right)=\\\\frac{1}{2}{E_1}\\\\log \\\\left( {D}\\\\left( {x} \\\\right) \\\\right)+ \\\\frac{1}{2}E_2 \\\\log \\\\left( 1-{D}\\\\left[ G_\\\\theta\\\\left(z \\\\right)\\\\right] \\\\right)$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      3. 过程：采用交替优化的方法：\\n\",\r\n",
      "-    \"         - $max_D min_G\\\\{\\\\ Loss\\\\left(\\\\theta_D \\\\theta_G \\\\right)={E_1}\\\\log \\\\left( {D_\\\\theta}\\\\left( {x} \\\\right) \\\\right)+ E_2 \\\\log \\\\left( 1-D_\\\\theta \\\\left[ G_\\\\theta\\\\left(z \\\\right)\\\\right] \\\\right)\\\\ \\\\}$\\n\",\r\n",
      "-    \"         - 先固定生成器 G, 优化判别器 D, 使得 D 的判别准确率最大化; \\n\",\r\n",
      "-    \"         - 然后固定判别器 D, 优化生成器 G, 使得 D 的判别准确率最小化\\n\",\r\n",
      "-    \"      4. GAN衍生模型\\n\",\r\n",
      "-    \"3. GAN的应用领域\\n\",\r\n",
      "-    \"   1. 视觉\\n\",\r\n",
      "-    \"   2. 语音语言\\n\",\r\n",
      "-    \"   3. 其他·\\n\",\r\n",
      "-    \"4. GAN的思考和展望\\n\",\r\n",
      "-    \"   1. 作为一种`生成式方法`, 有效解决了可建立自然性解释的数据的生成难题\\n\",\r\n",
      "-    \"   2. 将两个神经网络的对抗作为训练准则并且可以使用反向传播进行训练, 训练过程不需要效率较低的马尔科夫链方法, 也不需要做各种近似推理, 没有复杂的变分下界,\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料五：基于深度卷积神经网络的网络流量分类方法\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 引言\\n\",\r\n",
      "-    \"   1. 在网络流量分类领域的机器学习算法可以分为浅层学习和深度学习\\n\",\r\n",
      "-    \"   2. 浅层学习主要包括:支持向量机、决策树、 贝叶斯和 k-means\\n\",\r\n",
      "-    \"   3. 深度学习主要包括`**深度置信网络**`、`**卷积神经网络**`和`**递归神经网络**`等\\n\",\r\n",
      "-    \"   4. 基于离差标准化的卷积神经网络 min-max normalization convolutional neural network\\n\",\r\n",
      "-    \"2. 流量分类问题及描述\\n\",\r\n",
      "-    \"   1. 总体流程包括\\n\",\r\n",
      "-    \"      1. 网络数据的采集 现有的数据集 网络协议数据分析工具\\n\",\r\n",
      "-    \"      2. 带有准确背景信息数据集的生成\\n\",\r\n",
      "-    \"      3. 数据集的预处理，\\n\",\r\n",
      "-    \"      4. 流量特征的提取以及分类\\n\",\r\n",
      "-    \"   2. 采用卷积神经网络，构造合适的特征空间\\n\",\r\n",
      "-    \"      1. 对数据集进行数据预处理：将网络流量数据转化为灰度图片\\n\",\r\n",
      "-    \"      2. 将灰度图片作为卷积神经网络的输入数据进行学习\\n\",\r\n",
      "-    \"3. 基于改进卷积神经网络的网络流量分类方法\\n\",\r\n",
      "-    \"   1. 网络流量数据集的构建\\n\",\r\n",
      "-    \"      1. Moore 数据集\\n\",\r\n",
      "-    \"      2. 实际数据集\\n\",\r\n",
      "-    \"   2. 数据预处理\\n\",\r\n",
      "-    \"      1. 归一化：消除特征值的量纲，具有可比性\\n\",\r\n",
      "-    \"      2. 将构建好的矩阵中的每个元素作为一个像素点，矩阵中的值作为像素的灰度（白的程度\\n\",\r\n",
      "-    \"   3. 卷积神经网络\\n\",\r\n",
      "-    \"      1. 输入层、卷积层、池化层、全连接层、输出层\\n\",\r\n",
      "-    \"         1. 卷积层是卷积神经网络中最重要的一部分？\\n\",\r\n",
      "-    \"         2. 池化层也称为采样层？\\n\",\r\n",
      "-    \"         3. 全连接层通常位于卷积神经网络模型的最后位置，作用是计算网络的最终输出结果\\n\",\r\n",
      "-    \"   4. 训练过程\\n\",\r\n",
      "-    \"      1. 卷积层的前向传播形式为 激活函数为 ReLU 函数（去除负数\\n\",\r\n",
      "-    \"      2. 反向传播算法和BP神经网络类似，代价函数\\n\",\r\n",
      "-    \"   5. 改进的卷积神经网络结构\\n\",\r\n",
      "-    \"4. 实验测试与结果分析\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料六：《卷积神经网络研究综述_周飞燕.pdf》\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[大白话讲解卷积神经网络工作原理](https://www.bilibili.com/video/av35087157/?spm_id_from=333.788.videocard.0)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 引言\\n\",\r\n",
      "-    \"   1. 人工神经元网络 (Artificial Neural Network，ANN)是对生物神经网络的一种模拟和近似\\n\",\r\n",
      "-    \"   2. 反向传播网络 (Back Propagation Network，BP网络) **损失函数** => **通过训练自己得出卷积核**\\n\",\r\n",
      "-    \"   3. 逐层预训练 ”(layer-wise pre-training)\\n\",\r\n",
      "-    \"      1. 每次只无监督训练一层\\n\",\r\n",
      "-    \"      2. 将该层的训练结果作为其下一层的输入\\n\",\r\n",
      "-    \"      3. 有监督学习(BP算法)微调预训练好的网络\\n\",\r\n",
      "-    \"2. CNN概述\\n\",\r\n",
      "-    \"   1. 神经元：输入 权重 偏置 激励 输出\\n\",\r\n",
      "-    \"   2. 多层感知器：输入层、隐含层(一层或者多层)及输出层\\n\",\r\n",
      "-    \"   3. CNN：呈现出**图片结构**的数据\\n\",\r\n",
      "-    \"      1. 生物视觉感知\\n\",\r\n",
      "-    \"      2. 卷积层：通过`卷积核`提取出特征面，越高卷积层提取更高级的特征\\n\",\r\n",
      "-    \"      3. 池化层：降低特征面的分辨率\\n\",\r\n",
      "-    \"         1. 最大池化\\n\",\r\n",
      "-    \"         2. 平均池化\\n\",\r\n",
      "-    \"      4. 全连接层：用BP网络训练得到`权重`后，可导出分类结果\\n\",\r\n",
      "-    \"      5. `特征面`：根据实际应用进行设置\\n\",\r\n",
      "-    \"      6. 初始参数的确定（人为确定框架：找现成\\n\",\r\n",
      "-    \"         1. 卷积核数目、尺寸\\n\",\r\n",
      "-    \"         2. 池化大小、池化步长\\n\",\r\n",
      "-    \"         3. 全链接层神经元数量\\n\",\r\n",
      "-    \"3. 改进算法\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料七：基于深度置信网络的入侵检测模型\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[深度信念神经网络DBN最通俗易懂的教程](https://blog.csdn.net/u013631121/article/details/76794829?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Deep Learning（深度学习）学习笔记整理系列](https://blog.csdn.net/zouxy09/article/details/8775360)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 引言\\n\",\r\n",
      "-    \"2. 深度置信网络\\n\",\r\n",
      "-    \"   1. 由几个RBM和一层BP神经网络组成\\n\",\r\n",
      "-    \"   2. Restricting Boltzmann machine\\n\",\r\n",
      "-    \"      1. 一种两层随机神经网络\\n\",\r\n",
      "-    \"      2. 视觉层（v）\\n\",\r\n",
      "-    \"      3. 隐藏层（h）\\n\",\r\n",
      "-    \"      4. 能量函数\\n\",\r\n",
      "-    \"   3. BP神经网络\\n\",\r\n",
      "-    \"3. 入侵检测模型\\n\",\r\n",
      "-    \"4. 仿真与分析\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料八：基于深度学习的网络流量分类及异常检测方法研究_王伟\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 绪论\\n\",\r\n",
      "-    \"2. 基础知识和相关工作\\n\",\r\n",
      "-    \"   1. 网络流量分类方法\\n\",\r\n",
      "-    \"      1. 一般的网络流量分类\\n\",\r\n",
      "-    \"         1. 基于端口识别的分类方法\\n\",\r\n",
      "-    \"            1. 通过传输层的端口号识别 65535个 查表法\\n\",\r\n",
      "-    \"         2. 基于深层包检测的分类方法\\n\",\r\n",
      "-    \"            1. 检查整个数据包的内容\\n\",\r\n",
      "-    \"            2. 匹配固定的字符、字符串模式：也叫signature指纹\\n\",\r\n",
      "-    \"            3. 无法处理加密流量、未知流量\\n\",\r\n",
      "-    \"         3. 基于统计的分类方法\\n\",\r\n",
      "-    \"            1. 提取数据特征-机器学习\\n\",\r\n",
      "-    \"            2. 仅需特征数据，可用于加密流量\\n\",\r\n",
      "-    \"         4. 基于行为的分类方法\\n\",\r\n",
      "-    \"            1. 使用主机通信的行为信息：协议、端口、数量\\n\",\r\n",
      "-    \"      2. 恶意流量分类\\n\",\r\n",
      "-    \"      3. 加密流量分类\\n\",\r\n",
      "-    \"   2. 网络流量异常检测方法\\n\",\r\n",
      "-    \"   3. 深度学习\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料九：[读懂反向传播算法（bp算法）](https://www.jianshu.com/p/74bb815f612e)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"| 结构       | 神经元出    | 神经元入                                 | 神经元出 | 神经元入                                       |\\n\",\r\n",
      "-    \"| ---------- | ----------- | ---------------------------------------- | -------- | ---------------------------------------------- |\\n\",\r\n",
      "-    \"| 位置 层    | $l-1$       | $l$                                      | $l$      | $l+1$                                          |\\n\",\r\n",
      "-    \"| 位置 行    | $k$         | $j$                                      | $j$      | $i$                                            |\\n\",\r\n",
      "-    \"| 变量(向量) | $a_k^{l-1}$ | $a_k^{l-1}(A^{l-1})$                     | $a_j^{l}$ | $a_j^{l}(A^{l})$                               |\\n\",\r\n",
      "-    \"| 参数(向量) |             | $\\\\omega_{jk}^{l}(W_{j}^{l})$ , $b_j^{l}$ |          | $\\\\omega_{ij}^{l+1}(W_{i}^{l+1})$ , $b_i^{l+1}$ |\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"`正向运算过程：`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 神经元变量输入：$a_k^{l-1}$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 神经元参数输入：$\\\\omega_{jk}^{l}$，$b_j^{l}$\\n\",\r\n",
      "-    \"  > $k$取值范围为上一层神经元数，$j$对于单一神经元取值唯一\\n\",\r\n",
      "-    \"- 神经元处理：\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"  - $z_j^{l} = W_{j\\\\_}^{l}\\\\cdot A^{l-1}+b_j^{l}$\\n\",\r\n",
      "-    \"    > $a_k^{l-1}$,$\\\\omega_{jk}^{l}$ 排成$k$维列向量 $A^{l-1}$,$W_{j\\\\_}^{l}$\\n\",\r\n",
      "-    \"    >\\n\",\r\n",
      "-    \"    > 输入值对$l$层的任意神经元$j$都相同，故用$A^{l-1}$ 统一表示\\n\",\r\n",
      "-    \"  - $a_j^{l} = \\\\sigma(z_j^{l})$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 神经元输出：$a_j^{l} = \\\\sigma(z_j^{l})$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"`反向处理过程：`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 损失函数：$C(A^{L})$\\n\",\r\n",
      "-    \"  > L为总层数\\n\",\r\n",
      "-    \"- 定义：$\\\\delta_{j}^{l} \\\\equiv \\\\frac{\\\\partial C}{\\\\partial z_j^{l}},\\\\Delta^{l} \\\\equiv \\\\frac{\\\\partial C}{\\\\partial Z^{l}}$\\n\",\r\n",
      "-    \"  > 对$l$层$j$个神经元而言，中间变量$\\\\delta_{j}^{l}$为**损失函数**对**未激活的输出值**的偏微分\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 计算：\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"  - 递推公式：$\\\\delta_{j}^{l} =\\\\frac{\\\\partial C}{\\\\partial Z^{l+1}}\\\\cdot \\\\frac{\\\\partial Z^{l+1}}{\\\\partial z_j^{l}} = \\\\Delta^{l+1} \\\\cdot W_{\\\\_j}^{l+1} \\\\cdot \\\\sigma^{,}(z_j^{l})$\\n\",\r\n",
      "-    \"    > $z_i^{l+1},\\\\delta_i^{l+1},\\\\omega_{ij}^{l+1}$ 排成$j$维列向量 $Z^{l+1},\\\\Delta^{l+1},W_{\\\\_j}^{l+1}$\\n\",\r\n",
      "-    \"    >\\n\",\r\n",
      "-    \"    > $W_{\\\\_j}^{l+1}$ 由所有从神经元$j$指出去的边的权重$\\\\omega_{ij}^{l+1}$排成\\n\",\r\n",
      "-    \"    >\\n\",\r\n",
      "-    \"    > 与上文由所有指向神经元$j$的边的权重$\\\\omega_{kj}^{l}$不同！！\\n\",\r\n",
      "-    \"  - 末值：$\\\\delta_{j}^{L} =\\\\frac{\\\\partial C}{\\\\partial A^{L}}\\\\cdot \\\\frac{\\\\partial A^{L}}{\\\\partial z_j^{L}}$\\n\",\r\n",
      "-    \"    > 特例为单输出值情况\\n\",\r\n",
      "-    \"    >\\n\",\r\n",
      "-    \"    > $\\\\frac{\\\\partial C}{\\\\partial a^{L}}$ 取决于损失函数形式，一般为$\\\\frac{1-y}{1-a^{L}}-\\\\frac{y}{a^{L}}$\\n\",\r\n",
      "-    \"    >\\n\",\r\n",
      "-    \"    > $\\\\frac{\\\\partial a^{L}}{\\\\partial z^{L}}$ 取决于激活函数形式，sigmoid时为$a^{L}\\\\cdot(1-a^{L})$\\n\",\r\n",
      "-    \"    >\\n\",\r\n",
      "-    \"    > $\\\\delta^{L} = a^{L} - y$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"  - 用法：\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"    - $\\\\frac{\\\\partial C}{\\\\partial \\\\omega_{jk}^{l}} = \\\\frac{\\\\partial C}{\\\\partial z_{j}^{l}} \\\\cdot \\\\frac{\\\\partial z_{j}^{l}}{\\\\partial \\\\omega_{jk}^{l}} = \\\\delta_{j}^{L} \\\\cdot a_{k}^{l-1}$\\n\",\r\n",
      "-    \"  \\n\",\r\n",
      "-    \"    - $\\\\frac{\\\\partial C}{\\\\partial b_{j}^{l}} = \\\\frac{\\\\partial C}{\\\\partial z_{j}^{l}} \\\\cdot \\\\frac{\\\\partial z_{j}^{l}}{\\\\partial b_{j}^{l}} = \\\\delta_{j}^{L}$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 应用一：Tensorflow install\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Essential_documentation](https://tensorflow.google.cn/guide/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 安装\\n\",\r\n",
      "-    \"   1. 网址 [TensorFlow](https://tensorflow.google.cn/)\\n\",\r\n",
      "-    \"   2. 软件需求：python, pip, virtualenv\\\\conda\\n\",\r\n",
      "-    \"   3. 首次安装的版本可能并不契合网络资源所要求的tensorflow及其所需的python版本，因此可以使用conda创建虚拟环境选择合适的版本。\\n\",\r\n",
      "-    \"   4. tensorflow gpu 需要nvida显卡的支持，新款macbook搭载的是amd显卡，因此gpu版本安装问题无解\\n\",\r\n",
      "-    \"   5. 步骤\\n\",\r\n",
      "-    \"      - 下载anaconda_package（包含图形界面，对新手较友好） or [miniconda](https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/?C=M&O=A)\\n\",\r\n",
      "-    \"      - open anaconda powershell prompt\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ``` shell\\n\",\r\n",
      "-    \"      > conda --version\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      - 打开terminal，挂上SJTU_vpn\\n\",\r\n",
      "-    \"      - 通过conda创建虚拟环境并初始化python，激活刚刚创建的虚拟环境\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ``` shell\\n\",\r\n",
      "-    \"      > conda create -n tf pip python=3.7\\n\",\r\n",
      "-    \"      > conda activate tf\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      - 通过[清华源](https://mirror.tuna.tsinghua.edu.cn/help/pypi/)安装\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ``` shell\\n\",\r\n",
      "-    \"      (tf) > pip install -i https://pypi.tuna.tsinghua.edu.cn/simple tensorflow==2.1.0\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"2. 使用\\n\",\r\n",
      "-    \"   1. 步骤\\n\",\r\n",
      "-    \"      - 激活环境（也可以通过anaconda图形界面打开终端），进入python\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"        ``` shell\\n\",\r\n",
      "-    \"        > conda activate venv # 激活虚拟环境\\n\",\r\n",
      "-    \"        > python\\n\",\r\n",
      "-    \"        > conda deactivate #退出虚拟环境\\n\",\r\n",
      "-    \"        ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      - import tensorflow，导入tf.keras\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"          ```python\\n\",\r\n",
      "-    \"          import tensorflow as tf\\n\",\r\n",
      "-    \"          from tensorflow.keras import layers\\n\",\r\n",
      "-    \"          print(tf.__version__)\\n\",\r\n",
      "-    \"          print(tf.keras.__version__)\\n\",\r\n",
      "-    \"          ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"3. 问题修复\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   1. >\\\"Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\\\"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ```python\\n\",\r\n",
      "-    \"        >>> w=tf.Variable([[0.5,1.0]])\\n\",\r\n",
      "-    \"        2020-01-31 00:15:50.511182: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\\n\",\r\n",
      "-    \"        2020-01-31 00:15:50.527003: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7fc1dcc1a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\\n\",\r\n",
      "-    \"        2020-01-31 00:15:50.527021: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      问题所在：\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      [彻底解决“Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA”警告](https://blog.csdn.net/wlwlomo/article/details/82806118)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      [警告：Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA](https://blog.csdn.net/hq86937375/article/details/79696023)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      链接中提到，要换成支持cpu用AVX2编译的TensorFlow版本。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      如果您没有GPU并且希望尽可能多地利用CPU，那么如果您的CPU支持AVX，AVX2和FMA，则应该从针对CPU优化的源构建tensorflow。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      暂时解决方案：初学阶段重点在于理解原理，对于效率的提升不是重点，故忽略它（嘿嘿）\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      每次进入python环境时执行下列代码段，降低报警频率。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ```python\\n\",\r\n",
      "-    \"      import os\\n\",\r\n",
      "-    \"      os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   2. 版本问题\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ```python\\n\",\r\n",
      "-    \"      raise RuntimeError('The Session graph is empty.  Add operations to the '\\n\",\r\n",
      "-    \"      RuntimeError: The Session graph is empty.  Add operations to the graph before calling run().\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      暂时结论： tensorflow版本问题，函数使用方式产生了变更，一种方法是下载对应版本的tf，一种方法是改进使用代码。\\n\",\r\n",
      "-    \"\\n\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"markdown\",\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"source\": [\r\n",
      "-    \"## 应用二：tensorflow.keras\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[tensorflow-tutorials](https://tensorflow.google.cn/tutorials)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Keras 快速搭建神经网络 (莫烦 Python 教程)](https://www.bilibili.com/video/av16910214)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. QuickStart\\n\",\r\n",
      "-    \"2. Keras\\n\",\r\n",
      "-    \"3. Load data\\n\",\r\n",
      "-    \"4. Estimator\\n\",\r\n",
      "-    \"5. Customization\\n\",\r\n",
      "-    \"6. Distributed training\\n\",\r\n",
      "-    \"7. Images\\n\",\r\n",
      "-    \"   1. CNN\\n\",\r\n",
      "-    \"      - [tf.keras.layers.Conv2D](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/Conv2D)\\n\",\r\n",
      "-    \"        - filters 输出空间future map的维数/层数/高度、过滤器（卷积核）的数量\\n\",\r\n",
      "-    \"        - kernel_size 卷积核大小\\n\",\r\n",
      "-    \"        - strides 步长\\n\",\r\n",
      "-    \"        - activation 激活函数\\n\",\r\n",
      "-    \"        - use_bias 是否使用偏置向量b，默认为true\\n\",\r\n",
      "-    \"        - 作为第一层需要额外提供，例如input_shape=(128, 128, 3) 用于中的128x128 RGB图片\\n\",\r\n",
      "-    \"      - [tf.keras.layers.MaxPool2D](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/MaxPool2D)\\n\",\r\n",
      "-    \"        - pool_size (2, 2)将在两个空间维度上将输入减半\\n\",\r\n",
      "-    \"        - strides 步长 默认为上值\\n\",\r\n",
      "-    \"      - 输出形状： 具有形状的4D张量： (samples, filters, new_rows, new_cols)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ```py\\n\",\r\n",
      "-    \"      model = models.Sequential()\\n\",\r\n",
      "-    \"      model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\\n\",\r\n",
      "-    \"      #卷积核长与宽自己定，层数由输入图片层数决定，偏置bias b_i[1,1,1]，然后输出一张图 w_i[3,3,3]\\n\",\r\n",
      "-    \"      #输出次数自定 i[32]\\n\",\r\n",
      "-    \"      model.add(layers.MaxPooling2D((2, 2)))\\n\",\r\n",
      "-    \"      model.add(layers.Conv2D(64, (3, 3), activation='relu'))\\n\",\r\n",
      "-    \"      model.add(layers.MaxPooling2D((2, 2)))\\n\",\r\n",
      "-    \"      model.add(layers.Conv2D(64, (3, 3), activation='relu'))\\n\",\r\n",
      "-    \"      model.add(layers.Flatten()) # input 4*4*64 output 1024\\n\",\r\n",
      "-    \"      model.add(layers.Dense(64, activation='relu'))\\n\",\r\n",
      "-    \"      model.add(layers.Dense(10))\\n\",\r\n",
      "-    \"      model.summary()\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      Model: \\\"sequential_1\\\"\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      Layer (type)                 Output Shape              Param #\\n\",\r\n",
      "-    \"      =================================================================\\n\",\r\n",
      "-    \"      conv2d_3 (Conv2D)            (None, 30, 30, 32)        896 = (3*3*3+1)*32\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496 = (3*3*32+1)*64\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      conv2d_5 (Conv2D)            (None, 4, 4, 64)          36928 = (3*3*64+1)*64\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      flatten_1 (Flatten)          (None, 1024)              0\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      dense_2 (Dense)              (None, 64)                65600 = (1024+1)*64\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      dense_3 (Dense)              (None, 10)                650 = (64+1)*10\\n\",\r\n",
      "-    \"      =================================================================\\n\",\r\n",
      "-    \"      Total params: 122,570\\n\",\r\n",
      "-    \"      Trainable params: 122,570\\n\",\r\n",
      "-    \"      Non-trainable params: 0\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"8. Text\\n\",\r\n",
      "-    \"9. Structure data\\n\",\r\n",
      "-    \"10. Generative\\n\",\r\n",
      "-    \"    1. DCGan\\n\",\r\n",
      "-    \"       1. [batch nomolization](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/BatchNormalization)\\n\",\r\n",
      "-    \"          - [【 深度学习李宏毅 】 Batch Normalization （中文）](https://www.bilibili.com/video/av16540598/)\\n\",\r\n",
      "-    \"          - normalization 意义：损失函数对范围大数值对应参数w更敏感，需要不同对学习速率/同化到相同范围\\n\",\r\n",
      "-    \"            - 后层的变化总是落后与前层变化\\n\",\r\n",
      "-    \"            - 保证每个layer输出相对固定，\\n\",\r\n",
      "-    \"            - 问题？但每个layer输出的mean和variant是不断变化的\\n\",\r\n",
      "-    \"          - batch normalization：可以调大rate加快训练速度，解决vanishing gradient\\n\",\r\n",
      "-    \"            - 可以在激活前后应用（推荐先normalization后activation：让值落在零的附近再激活效果较好）\\n\",\r\n",
      "-    \"            - batch 一串 把多个样本\\n\",\r\n",
      "-    \"            - 对每个layer的一串输出z求出z均值和z方差，然后根据均值和方差进行normalization\\n\",\r\n",
      "-    \"            - 如何bp？z均值和z方差也视为变量，而normalization后可以进行放缩和平移（常量）\\n\",\r\n",
      "-    \"            - training时的z均值和z方差在不断变化，在考虑正确率作为权重\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   ```py\\n\",\r\n",
      "-    \"   #generator\\n\",\r\n",
      "-    \"   def make_generator_model():\\n\",\r\n",
      "-    \"      model = tf.keras.Sequential()\\n\",\r\n",
      "-    \"      model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\\n\",\r\n",
      "-    \"      model.add(layers.BatchNormalization())\\n\",\r\n",
      "-    \"      model.add(layers.LeakyReLU())\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      model.add(layers.Reshape((7, 7, 256)))\\n\",\r\n",
      "-    \"      assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\\n\",\r\n",
      "-    \"      # b=0: not use bias\\n\",\r\n",
      "-    \"      assert model.output_shape == (None, 7, 7, 128)\\n\",\r\n",
      "-    \"      model.add(layers.BatchNormalization())\\n\",\r\n",
      "-    \"      model.add(layers.LeakyReLU())\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\\n\",\r\n",
      "-    \"      assert model.output_shape == (None, 14, 14, 64)\\n\",\r\n",
      "-    \"      model.add(layers.BatchNormalization())\\n\",\r\n",
      "-    \"      model.add(layers.LeakyReLU())\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\\n\",\r\n",
      "-    \"      assert model.output_shape == (None, 28, 28, 1)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      return model\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   generator = make_generator_model()\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   Layer (type)                 Output Shape              Param #\\n\",\r\n",
      "-    \"   =================================================================\\n\",\r\n",
      "-    \"   dense (Dense)                (None, 12544)             1254400 = 7*7*256*100\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   batch_normalization (BatchNo (None, 12544)             50176 = 12544*4????\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   leaky_re_lu (LeakyReLU)      (None, 12544)             0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   reshape (Reshape)            (None, 7, 7, 256)         0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200 = (5*5*256+0)*128\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   batch_normalization_1 (Batch (None, 7, 7, 128)         512 = 128*4\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800 = (5*5*128+0)*64\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   batch_normalization_2 (Batch (None, 14, 14, 64)        256 = 64*4\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1600 = (5*5*64+0)*1\\n\",\r\n",
      "-    \"   =================================================================\\n\",\r\n",
      "-    \"   Total params: 2,330,944\\n\",\r\n",
      "-    \"   Trainable params: 2,305,472\\n\",\r\n",
      "-    \"   Non-trainable params: 25,472\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   #discriminator\\n\",\r\n",
      "-    \"   def make_discriminator_model():\\n\",\r\n",
      "-    \"      model = tf.keras.Sequential()\\n\",\r\n",
      "-    \"      model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\\n\",\r\n",
      "-    \"                                       input_shape=[28, 28, 1]))\\n\",\r\n",
      "-    \"      model.add(layers.LeakyReLU())\\n\",\r\n",
      "-    \"      # [tf.keras.layers.LeakyReLU](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/LeakyReLU)\\n\",\r\n",
      "-    \"      model.add(layers.Dropout(0.3))\\n\",\r\n",
      "-    \"      # [tf.keras.layers.Dropout](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/Dropout) 将输入单元的一部分随机设置为0，这有助于防止过拟合。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\\n\",\r\n",
      "-    \"      model.add(layers.LeakyReLU())\\n\",\r\n",
      "-    \"      model.add(layers.Dropout(0.3))\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      model.add(layers.Flatten())\\n\",\r\n",
      "-    \"      model.add(layers.Dense(1))\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      return model\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   discriminator = make_discriminator_model()\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   Layer (type)                 Output Shape              Param #\\n\",\r\n",
      "-    \"   =================================================================\\n\",\r\n",
      "-    \"   conv2d (Conv2D)              (None, 14, 14, 64)        1664 = (5*5*1+1)*64\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   dropout (Dropout)            (None, 14, 14, 64)        0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928 = (5*5*64+1)*128\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   dropout_1 (Dropout)          (None, 7, 7, 128)         0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   flatten (Flatten)            (None, 6272)              0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   dense_1 (Dense)              (None, 1)                 6273\\n\",\r\n",
      "-    \"   =================================================================\\n\",\r\n",
      "-    \"   Total params: 212,865\\n\",\r\n",
      "-    \"   Trainable params: 212,865\\n\",\r\n",
      "-    \"   Non-trainable params: 0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   # Generator loss\\n\",\r\n",
      "-    \"   def generator_loss(fake_output):\\n\",\r\n",
      "-    \"      return cross_entropy(tf.ones_like(fake_output), fake_output)\\n\",\r\n",
      "-    \"   # Discriminator loss\\n\",\r\n",
      "-    \"   def discriminator_loss(real_output, fake_output):\\n\",\r\n",
      "-    \"      real_loss = cross_entropy(tf.ones_like(real_output), real_output)\\n\",\r\n",
      "-    \"      fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\\n\",\r\n",
      "-    \"      total_loss = real_loss + fake_loss\\n\",\r\n",
      "-    \"      return total_loss\\n\",\r\n",
      "-    \"   # discriminator and the generator optimizers ?????\\n\",\r\n",
      "-    \"   # [tf.keras.optimizers.Adam](https://tensorflow.google.cn/api_docs/python/tf/keras/optimizers/Adam?hl=en)\\n\",\r\n",
      "-    \"   generator_optimizer = tf.keras.optimizers.Adam(1e-4) #实现Adam算法的优化器。学习率\\n\",\r\n",
      "-    \"   discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   # training loop!!!\\n\",\r\n",
      "-    \"   def train_step(images):\\n\",\r\n",
      "-    \"      noise = tf.random.normal([BATCH_SIZE, noise_dim]) #根据batch大小生成随机数据\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\\n\",\r\n",
      "-    \"         generated_images = generator(noise, training=True) #生成器，输出图片数据(None, 28, 28, 1)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         real_output = discriminator(images, training=True) #判别器，输出判别数据(None, 1)\\n\",\r\n",
      "-    \"         fake_output = discriminator(generated_images, training=True) #判别器，输出判别数据(None, 1)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         gen_loss = generator_loss(fake_output)\\n\",\r\n",
      "-    \"         disc_loss = discriminator_loss(real_output, fake_output)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables) # 调用GradientTape.gradient方法，就会释放GradientTape拥有的资源\\n\",\r\n",
      "-    \"      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) #input:List of (gradient, variable) pairs\\n\",\r\n",
      "-    \"      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   def train(dataset, epochs):\\n\",\r\n",
      "-    \"      for epoch in range(epochs):\\n\",\r\n",
      "-    \"         start = time.time()\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         for image_batch in dataset: #BATCH_SIZE = 256\\n\",\r\n",
      "-    \"            train_step(image_batch) #image_batch.shape=(256, 28, 28, 1)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         # Produce images for the GIF as we go\\n\",\r\n",
      "-    \"         display.clear_output(wait=True)\\n\",\r\n",
      "-    \"         generate_and_save_images(generator,\\n\",\r\n",
      "-    \"                                 epoch + 1,\\n\",\r\n",
      "-    \"                                 seed)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         # Save the model every 15 epochs\\n\",\r\n",
      "-    \"         if (epoch + 1) % 15 == 0:\\n\",\r\n",
      "-    \"            checkpoint.save(file_prefix = checkpoint_prefix)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      # Generate after the final epoch\\n\",\r\n",
      "-    \"      display.clear_output(wait=True)\\n\",\r\n",
      "-    \"      generate_and_save_images(generator,\\n\",\r\n",
      "-    \"                                 epochs,\\n\",\r\n",
      "-    \"                                 seed)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   train(train_dataset, EPOCHS) #EPOCHS = 50 迭代五十次\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   ```\\n\"\r\n",
      "-   ]\r\n",
      "-  }\r\n",
      "- ],\r\n",
      "- \"metadata\": {\r\n",
      "-  \"kernelspec\": {\r\n",
      "-   \"display_name\": \"Python 3\",\r\n",
      "-   \"language\": \"python\",\r\n",
      "-   \"name\": \"python3\"\r\n",
      "-  },\r\n",
      "-  \"language_info\": {\r\n",
      "-   \"codemirror_mode\": {\r\n",
      "-    \"name\": \"ipython\",\r\n",
      "-    \"version\": 3\r\n",
      "-   },\r\n",
      "-   \"file_extension\": \".py\",\r\n",
      "-   \"mimetype\": \"text/x-python\",\r\n",
      "-   \"name\": \"python\",\r\n",
      "-   \"nbconvert_exporter\": \"python\",\r\n",
      "-   \"pygments_lexer\": \"ipython3\",\r\n",
      "-   \"version\": \"3.6.10\"\r\n",
      "-  }\r\n",
      "- },\r\n",
      "- \"nbformat\": 4,\r\n",
      "- \"nbformat_minor\": 4\r\n",
      "-}\r\n",
      "diff --git a/lsq/README.ipynb b/lsq/README.ipynb\r\n",
      "deleted file mode 100644\r\n",
      "index 1529d0d..0000000\r\n",
      "--- a/lsq/README.ipynb\r\n",
      "+++ /dev/null\r\n",
      "@@ -1,447 +0,0 @@\r\n",
      "-{\r\n",
      "- \"cells\": [\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"markdown\",\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"source\": [\r\n",
      "-    \"# jupyter note sync with github\\n\",\r\n",
      "-    \"[用GitPython操作Git库 · 零壹軒·笔记](https://note.qidong.name/2018/01/gitpython/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## linux\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## server\\n\",\r\n",
      "-    \"\\n\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"markdown\",\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"source\": [\r\n",
      "-    \"# git\\n\",\r\n",
      "-    \"[创建版本库 - 廖雪峰的官方网站](https://www.liaoxuefeng.com/wiki/896043488029600/896827951938304)\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": 1,\r\n",
      "-   \"metadata\": {\r\n",
      "-    \"scrolled\": true\r\n",
      "-   },\r\n",
      "-   \"outputs\": [\r\n",
      "-    {\r\n",
      "-     \"name\": \"stdout\",\r\n",
      "-     \"output_type\": \"stream\",\r\n",
      "-     \"text\": [\r\n",
      "-      \"# On branch master\\r\\n\",\r\n",
      "-      \"#\\r\\n\",\r\n",
      "-      \"# Initial commit\\r\\n\",\r\n",
      "-      \"#\\r\\n\",\r\n",
      "-      \"# Changes to be committed:\\r\\n\",\r\n",
      "-      \"#   (use \\\"git rm --cached <file>...\\\" to unstage)\\r\\n\",\r\n",
      "-      \"#\\r\\n\",\r\n",
      "-      \"#\\tnew file:   .ipynb_checkpoints/README-checkpoint.ipynb\\r\\n\",\r\n",
      "-      \"#\\tnew file:   .ipynb_checkpoints/lsq_note-checkpoint.ipynb\\r\\n\",\r\n",
      "-      \"#\\tnew file:   README.ipynb\\r\\n\",\r\n",
      "-      \"#\\tnew file:   TABOR\\r\\n\",\r\n",
      "-      \"#\\tnew file:   database_sqlite/.ipynb_checkpoints/database_sqlite-checkpoint.ipynb\\r\\n\",\r\n",
      "-      \"#\\tnew file:   database_sqlite/.ipynb_checkpoints/search-checkpoint.ipynb\\r\\n\",\r\n",
      "-      \"#\\tnew file:   database_sqlite/database_sqlite.ipynb\\r\\n\",\r\n",
      "-      \"#\\tnew file:   database_sqlite/search.ipynb\\r\\n\",\r\n",
      "-      \"#\\tnew file:   database_sqlite/test.db\\r\\n\",\r\n",
      "-      \"#\\tnew file:   database_sqlite/test2.db\\r\\n\",\r\n",
      "-      \"#\\tnew file:   lsq_note.ipynb\\r\\n\",\r\n",
      "-      \"#\\tnew file:   lsq_note.md\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/.ipynb_checkpoints/web-checkpoint.ipynb\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/.ipynb_checkpoints/startproject-checkpoint.ipynb\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/HelloWorld/__init__.py\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/HelloWorld/__pycache__/__init__.cpython-36.pyc\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/HelloWorld/__pycache__/settings.cpython-36.pyc\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/HelloWorld/__pycache__/urls.cpython-36.pyc\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/HelloWorld/__pycache__/view.cpython-36.pyc\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/HelloWorld/__pycache__/wsgi.cpython-36.pyc\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/HelloWorld/asgi.py\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/HelloWorld/settings.py\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/HelloWorld/urls.py\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/HelloWorld/view.py\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/HelloWorld/wsgi.py\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/db.sqlite3\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/manage.py\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/HelloWorld/startproject.ipynb\\r\\n\",\r\n",
      "-      \"#\\tnew file:   web/web.ipynb\\r\\n\",\r\n",
      "-      \"#\\r\\n\",\r\n",
      "-      \"# Changes not staged for commit:\\r\\n\",\r\n",
      "-      \"#   (use \\\"git add <file>...\\\" to update what will be committed)\\r\\n\",\r\n",
      "-      \"#   (use \\\"git checkout -- <file>...\\\" to discard changes in working directory)\\r\\n\",\r\n",
      "-      \"#   (commit or discard the untracked or modified content in submodules)\\r\\n\",\r\n",
      "-      \"#\\r\\n\",\r\n",
      "-      \"#\\tmodified:   .ipynb_checkpoints/README-checkpoint.ipynb\\r\\n\",\r\n",
      "-      \"#\\tmodified:   README.ipynb\\r\\n\",\r\n",
      "-      \"#\\tmodified:   TABOR (modified content, untracked content)\\r\\n\",\r\n",
      "-      \"#\\r\\n\"\r\n",
      "-     ]\r\n",
      "-    }\r\n",
      "-   ],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!git status\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": 6,\r\n",
      "-   \"metadata\": {\r\n",
      "-    \"collapsed\": true\r\n",
      "-   },\r\n",
      "-   \"outputs\": [\r\n",
      "-    {\r\n",
      "-     \"name\": \"stdout\",\r\n",
      "-     \"output_type\": \"stream\",\r\n",
      "-     \"text\": [\r\n",
      "-      \"diff --git a/README.ipynb b/README.ipynb\\r\\n\",\r\n",
      "-      \"index e2b2f9a..64e5d8e 100644\\r\\n\",\r\n",
      "-      \"--- a/README.ipynb\\r\\n\",\r\n",
      "-      \"+++ b/README.ipynb\\r\\n\",\r\n",
      "-      \"@@ -22,29 +22,43 @@\\r\\n\",\r\n",
      "-      \"      \\\"name\\\": \\\"stdout\\\",\\r\\n\",\r\n",
      "-      \"      \\\"output_type\\\": \\\"stream\\\",\\r\\n\",\r\n",
      "-      \"      \\\"text\\\": [\\r\\n\",\r\n",
      "-      \"-      \\\"Collecting GitPython\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"  Using cached GitPython-3.1.0-py3-none-any.whl (450 kB)\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"Collecting gitdb<5,>=4.0.1\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"  Using cached gitdb-4.0.2-py3-none-any.whl (63 kB)\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"Collecting smmap<4,>=3.0.1\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"  Using cached smmap-3.0.1-py2.py3-none-any.whl (25 kB)\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"Installing collected packages: smmap, gitdb, GitPython\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-      \\\"Successfully installed GitPython-3.1.0 gitdb-4.0.2 smmap-3.0.1\\\\n\\\"\\r\\n\",\r\n",
      "-      \"+      \\\"# On branch master\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"# Initial commit\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"# Untracked files:\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#   (use \\\\\\\"git add <file>...\\\\\\\" to include in what will be committed)\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\t.ipynb_checkpoints/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tREADME.ipynb\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tTABOR/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tdatabase_sqlite/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tlsq_note.ipynb\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tlsq_note.md\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tweb/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"nothing added to commit but untracked files present (use \\\\\\\"git add\\\\\\\" to track)\\\\r\\\\n\\\"\\r\\n\",\r\n",
      "-      \"      ]\\r\\n\",\r\n",
      "-      \"     }\\r\\n\",\r\n",
      "-      \"    ],\\r\\n\",\r\n",
      "-      \"    \\\"source\\\": [\\r\\n\",\r\n",
      "-      \"-    \\\"!pip install GitPython\\\"\\r\\n\",\r\n",
      "-      \"+    \\\"!git commit\\\"\\r\\n\",\r\n",
      "-      \"    ]\\r\\n\",\r\n",
      "-      \"   },\\r\\n\",\r\n",
      "-      \"   {\\r\\n\",\r\n",
      "-      \"    \\\"cell_type\\\": \\\"code\\\",\\r\\n\",\r\n",
      "-      \"    \\\"execution_count\\\": 2,\\r\\n\",\r\n",
      "-      \"    \\\"metadata\\\": {},\\r\\n\",\r\n",
      "-      \"-   \\\"outputs\\\": [],\\r\\n\",\r\n",
      "-      \"+   \\\"outputs\\\": [\\r\\n\",\r\n",
      "-      \"+    {\\r\\n\",\r\n",
      "-      \"+     \\\"name\\\": \\\"stdout\\\",\\r\\n\",\r\n",
      "-      \"+     \\\"output_type\\\": \\\"stream\\\",\\r\\n\",\r\n",
      "-      \"+     \\\"text\\\": [\\r\\n\",\r\n",
      "-      \"+      \\\"/root/innoproject/lsq\\\\r\\\\n\\\"\\r\\n\",\r\n",
      "-      \"+     ]\\r\\n\",\r\n",
      "-      \"+    }\\r\\n\",\r\n",
      "-      \"+   ],\\r\\n\",\r\n",
      "-      \"    \\\"source\\\": [\\r\\n\",\r\n",
      "-      \"-    \\\"import git\\\\n\\\",\\r\\n\",\r\n",
      "-      \"-    \\\"new_repo = git.Repo.clone_from(url='https://github.com/Steven147/InnoProject.git', to_path='../github')\\\\n\\\"\\r\\n\",\r\n",
      "-      \"+    \\\"!pwd\\\"\\r\\n\",\r\n",
      "-      \"    ]\\r\\n\",\r\n",
      "-      \"   },\\r\\n\",\r\n",
      "-      \"   {\\r\\n\",\r\n",
      "-      \"@@ -53,21 +67,48 @@\\r\\n\",\r\n",
      "-      \"    \\\"metadata\\\": {},\\r\\n\",\r\n",
      "-      \"    \\\"outputs\\\": [\\r\\n\",\r\n",
      "-      \"     {\\r\\n\",\r\n",
      "-      \"-     \\\"data\\\": {\\r\\n\",\r\n",
      "-      \"-      \\\"text/plain\\\": [\\r\\n\",\r\n",
      "-      \"-       \\\"<git.Commit \\\\\\\"f95367ade7fc041a427e1e5068a301f302c16e19\\\\\\\">\\\"\\r\\n\",\r\n",
      "-      \"-      ]\\r\\n\",\r\n",
      "-      \"-     },\\r\\n\",\r\n",
      "-      \"-     \\\"execution_count\\\": 3,\\r\\n\",\r\n",
      "-      \"-     \\\"metadata\\\": {},\\r\\n\",\r\n",
      "-      \"-     \\\"output_type\\\": \\\"execute_result\\\"\\r\\n\",\r\n",
      "-      \"+     \\\"name\\\": \\\"stdout\\\",\\r\\n\",\r\n",
      "-      \"+     \\\"output_type\\\": \\\"stream\\\",\\r\\n\",\r\n",
      "-      \"+     \\\"text\\\": [\\r\\n\",\r\n",
      "-      \"+      \\\"# On branch master\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"# Initial commit\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"# Untracked files:\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#   (use \\\\\\\"git add <file>...\\\\\\\" to include in what will be committed)\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\t.ipynb_checkpoints/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tREADME.ipynb\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tTABOR/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tdatabase_sqlite/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tlsq_note.ipynb\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tlsq_note.md\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"#\\\\tweb/\\\\r\\\\n\\\",\\r\\n\",\r\n",
      "-      \"+      \\\"nothing added to commit but untracked files present (use \\\\\\\"git add\\\\\\\" to track)\\\\r\\\\n\\\"\\r\\n\",\r\n",
      "-      \"+     ]\\r\\n\",\r\n",
      "-      \"     }\\r\\n\",\r\n",
      "-      \"    ],\\r\\n\",\r\n",
      "-      \"    \\\"source\\\": [\\r\\n\",\r\n",
      "-      \"-    \\\"new_repo.index.commit('initialize')\\\"\\r\\n\",\r\n",
      "-      \"+    \\\"!git status\\\"\\r\\n\",\r\n",
      "-      \"    ]\\r\\n\",\r\n",
      "-      \"   },\\r\\n\",\r\n",
      "-      \"   {\\r\\n\",\r\n",
      "-      \"+   \\\"cell_type\\\": \\\"code\\\",\\r\\n\",\r\n",
      "-      \"+   \\\"execution_count\\\": 5,\\r\\n\",\r\n",
      "-      \"+   \\\"metadata\\\": {},\\r\\n\",\r\n",
      "-      \"+   \\\"outputs\\\": [],\\r\\n\",\r\n",
      "-      \"+   \\\"source\\\": [\\r\\n\",\r\n",
      "-      \"+    \\\"!git add .\\\"\\r\\n\",\r\n",
      "-      \"+   ]\\r\\n\",\r\n",
      "-      \"+  },\\r\\n\",\r\n",
      "-      \"+  {\\r\\n\",\r\n",
      "-      \"+   \\\"cell_type\\\": \\\"code\\\",\\r\\n\",\r\n",
      "-      \"+   \\\"execution_count\\\": null,\\r\\n\",\r\n",
      "-      \"+   \\\"metadata\\\": {},\\r\\n\",\r\n",
      "-      \"+   \\\"outputs\\\": [],\\r\\n\",\r\n",
      "-      \"+   \\\"source\\\": []\\r\\n\",\r\n",
      "-      \"+  },\\r\\n\",\r\n",
      "-      \"+  {\\r\\n\",\r\n",
      "-      \"    \\\"cell_type\\\": \\\"markdown\\\",\\r\\n\",\r\n",
      "-      \"    \\\"metadata\\\": {},\\r\\n\",\r\n",
      "-      \"    \\\"source\\\": [\\r\\n\",\r\n",
      "-      \"diff --git a/TABOR b/TABOR\\r\\n\",\r\n",
      "-      \"--- a/TABOR\\r\\n\",\r\n",
      "-      \"+++ b/TABOR\\r\\n\",\r\n",
      "-      \"@@ -1 +1 @@\\r\\n\",\r\n",
      "-      \"-Subproject commit 27b23895a3182d0f2d4c259b2f09ed1e859a94ad\\r\\n\",\r\n",
      "-      \"+Subproject commit 27b23895a3182d0f2d4c259b2f09ed1e859a94ad-dirty\\r\\n\"\r\n",
      "-     ]\r\n",
      "-    }\r\n",
      "-   ],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!git diff\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": 2,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [\r\n",
      "-    {\r\n",
      "-     \"name\": \"stdout\",\r\n",
      "-     \"output_type\": \"stream\",\r\n",
      "-     \"text\": [\r\n",
      "-      \"/root/innoproject/lsq\\r\\n\"\r\n",
      "-     ]\r\n",
      "-    }\r\n",
      "-   ],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!pwd\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": 5,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!git add .\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": 7,\r\n",
      "-   \"metadata\": {\r\n",
      "-    \"collapsed\": true\r\n",
      "-   },\r\n",
      "-   \"outputs\": [\r\n",
      "-    {\r\n",
      "-     \"name\": \"stdout\",\r\n",
      "-     \"output_type\": \"stream\",\r\n",
      "-     \"text\": [\r\n",
      "-      \"\\u001b7\\u001b[?47h\\u001b[?1h\\u001b=\\u001b[1;24r\\u001b[m\\u001b[H\\u001b[2J\\u001b[24;1H\\\".git/COMMIT_EDITMSG\\\" 51L, 2142C\\u001b[2;1H# Please enter the commit message for your changes. Lines starting\\n\",\r\n",
      "-      \"# with '#' will be ignored, and an empty message aborts the commit.\\n\",\r\n",
      "-      \"#\\n\",\r\n",
      "-      \"# Committer: root <root@localhost.localdomain>\\n\",\r\n",
      "-      \"#\\n\",\r\n",
      "-      \"# On branch master\\n\",\r\n",
      "-      \"#\\n\",\r\n",
      "-      \"# Initial commit\\n\",\r\n",
      "-      \"#\\n\",\r\n",
      "-      \"# Changes to be committed:\\n\",\r\n",
      "-      \"#   (use \\\"git rm --cached <file>...\\\" to unstage)\\n\",\r\n",
      "-      \"#\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   .ipynb_checkpoints/README-checkpoint.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   .ipynb_checkpoints/lsq_note-checkpoint.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   README.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   TABOR\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   database_sqlite/.ipynb_checkpoints/database_sqlite-checkpoinn\\u001b[19;1Ht.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   database_sqlite/.ipynb_checkpoints/search-checkpoint.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   database_sqlite/database_sqlite.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   database_sqlite/search.ipynb\\n\",\r\n",
      "-      \"#\\u001b[7Cnew file:   database_sqlite/test.db\\u001b[1;1H\\u001b[24;1HType  :quit<Enter>  to exit Vim\\u001b[24;32H\\u001b[K\\u0007\\u001b[1;1H\"\r\n",
      "-     ]\r\n",
      "-    }\r\n",
      "-   ],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!git commit\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": null,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!git remote add origin git@github.com:Steven147/Innoproject.git\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": null,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [\r\n",
      "-    {\r\n",
      "-     \"name\": \"stdout\",\r\n",
      "-     \"output_type\": \"stream\",\r\n",
      "-     \"text\": [\r\n",
      "-      \"The authenticity of host 'github.com (13.250.177.223)' can't be established.\\r\\n\",\r\n",
      "-      \"RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.\\r\\n\",\r\n",
      "-      \"RSA key fingerprint is MD5:16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.\\r\\n\",\r\n",
      "-      \"Are you sure you want to continue connecting (yes/no)? \"\r\n",
      "-     ]\r\n",
      "-    }\r\n",
      "-   ],\r\n",
      "-   \"source\": [\r\n",
      "-    \"!git push origin master\\n\",\r\n",
      "-    \"!yes\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"markdown\",\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"source\": [\r\n",
      "-    \"# 笔记 林绍钦\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[本文链接InnoProject/lsq\\\\_note.md](https://github.com/Steven147/InnoProject/blob/master/lsq/lsq_note.md)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 连接综述\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- termius\\n\",\r\n",
      "-    \"  - `sudo su -`\\n\",\r\n",
      "-    \"  - zft13917331612\\n\",\r\n",
      "-    \"  - `conda activate lsq_py36_tfgpu`\\n\",\r\n",
      "-    \"  - `jupyter notebook --no-browser --port=8889 --allow-root --certfile=mycert.pem --keyfile mykey.key`\\n\",\r\n",
      "-    \"- terminal\\n\",\r\n",
      "-    \"  - `ssh -N -f -L localhost:8888:localhost:8889 -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"  - zft13917331612\\n\",\r\n",
      "-    \"- [localhost](https://localhost:8888/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## SSH远程连接\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- Linux/MacOS 作为终端\\n\",\r\n",
      "-    \"  - IP地址:`202.120.39.26:10151`,账号密码:`ipp20aitrojan`,`zft13917331612`\\n\",\r\n",
      "-    \"  - 连接命令:`ssh -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"  - 输入密码:`zft13917331612`\\n\",\r\n",
      "-    \"  - 登入成功！:`[ipp20aitrojan@localhost ~]$ .....`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 终端软件：[Introduction - Termius Documentation](https://docs.termius.com/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## jupyter notebook 远程连接\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[远程访问服务器Jupyter Notebook的两种方法 - 简书](https://www.jianshu.com/p/8fc3cd032d3c)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Running a notebook server — Jupyter Notebook 7.0.0.dev0 documentation](https://jupyter-notebook.readthedocs.io/en/latest/public_server.html#notebook-server-security)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 打开终端1：将本地端口号8888映射到服务器8889该过程只需要执行一次(通过`killall ssh`可以取消执行)\\n\",\r\n",
      "-    \"  - `ssh -N -f -L localhost:8888:localhost:8889 -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"  - 输入密码:`zft13917331612`\\n\",\r\n",
      "-    \"- 打开终端2\\n\",\r\n",
      "-    \"  - 使用SSH连接\\n\",\r\n",
      "-    \"    - 连接命令:`ssh -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"    - 输入密码:`zft13917331612`\\n\",\r\n",
      "-    \"  - 新建conda环境（python3），在新环境里下载jupyter notebook：`pip install notebook`\\n\",\r\n",
      "-    \"  - 配置jupyter环境（省略，因为已经配好了）\\n\",\r\n",
      "-    \"  - `jupyter notebook --no-browser --port=8889 --allow-root --certfile=mycert.pem --keyfile mykey.key`\\n\",\r\n",
      "-    \"- 用网页打开链接[localhost](https://localhost:8888/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## Linux 基本使用\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [27个常用的 Linux 命令 - 简书](https://www.jianshu.com/p/0056d671ea6d)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [Ranger 用法总结 | 盼 の 欲](http://www.huangpan.net/posts/ji-ke/2019-08-21-ranger.html)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- `sudo su -`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## tf环境搭建\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"### 0 资源链接\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Anaconda Python/R Distribution - Free Download](https://www.anaconda.com/distribution/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Install TensorFlow 2](https://tensorflow.google.cn/install)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[tensorflow-tutorials](https://tensorflow.google.cn/tutorials)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"### 1 pip安装tf-gpu流程\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [Anaconda Python/R Distribution - Free Download](https://www.anaconda.com/distribution/)\\n\",\r\n",
      "-    \"  - Windows 下载安装包进行安装（过程略\\n\",\r\n",
      "-    \"  - Linux:\\n\",\r\n",
      "-    \"    - `$ wget https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh`\\n\",\r\n",
      "-    \"    - 运行shell\\n\",\r\n",
      "-    \"    - 将anaconda的bin目录加入PATH:`$ echo 'export PATH=\\\"~/anaconda3/bin:$PATH\\\"' >> ~/.bashrc`\\n\",\r\n",
      "-    \"    - 更新bashrc以立即生效:`$ source ~/.bashrc`\\n\",\r\n",
      "-    \"  - 检验:`conda --version`\\n\",\r\n",
      "-    \"  - [Conda常用命令整理\\\\_运维\\\\_Working. Playing.-CSDN博客](https://blog.csdn.net/menc15/article/details/71477949)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- （已经安装好了现成环境py36_tfgpu，拷贝为lsq_py36_tfgpu）`conda create --name lsq_py36_tfgpu --clone py36_tfgpu`\\n\",\r\n",
      "-    \"- `conda activate lsq_py36_tfgpu`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [Install TensorFlow 2](https://tensorflow.google.cn/install)\\n\",\r\n",
      "-    \"  - 检验安装\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"    ```py\\n\",\r\n",
      "-    \"    import tensorflow as tf\\n\",\r\n",
      "-    \"    tf.test.is_gpu_available()\\n\",\r\n",
      "-    \"    ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"### 2 错误处理\\n\",\r\n",
      "-    \"\\n\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"code\",\r\n",
      "-   \"execution_count\": null,\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"outputs\": [],\r\n",
      "-   \"source\": []\r\n",
      "-  }\r\n",
      "- ],\r\n",
      "- \"metadata\": {\r\n",
      "-  \"kernelspec\": {\r\n",
      "-   \"display_name\": \"Python 3\",\r\n",
      "-   \"language\": \"python\",\r\n",
      "-   \"name\": \"python3\"\r\n",
      "-  },\r\n",
      "-  \"language_info\": {\r\n",
      "-   \"codemirror_mode\": {\r\n",
      "-    \"name\": \"ipython\",\r\n",
      "-    \"version\": 3\r\n",
      "-   },\r\n",
      "-   \"file_extension\": \".py\",\r\n",
      "-   \"mimetype\": \"text/x-python\",\r\n",
      "-   \"name\": \"python\",\r\n",
      "-   \"nbconvert_exporter\": \"python\",\r\n",
      "-   \"pygments_lexer\": \"ipython3\",\r\n",
      "-   \"version\": \"3.6.10\"\r\n",
      "-  }\r\n",
      "- },\r\n",
      "- \"nbformat\": 4,\r\n",
      "- \"nbformat_minor\": 4\r\n",
      "-}\r\n",
      "diff --git a/lsq/TABOR b/lsq/TABOR\r\n",
      "--- a/lsq/TABOR\r\n",
      "+++ b/lsq/TABOR\r\n",
      "@@ -1 +1 @@\r\n",
      "-Subproject commit 27b23895a3182d0f2d4c259b2f09ed1e859a94ad\r\n",
      "+Subproject commit 27b23895a3182d0f2d4c259b2f09ed1e859a94ad-dirty\r\n",
      "diff --git a/lsq/lsq_note.ipynb b/lsq/lsq_note.ipynb\r\n",
      "deleted file mode 100644\r\n",
      "index ba4786a..0000000\r\n",
      "--- a/lsq/lsq_note.ipynb\r\n",
      "+++ /dev/null\r\n",
      "@@ -1,853 +0,0 @@\r\n",
      "-{\r\n",
      "- \"cells\": [\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"markdown\",\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"source\": [\r\n",
      "-    \"# 笔记 林绍钦\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[本文链接InnoProject/lsq\\\\_note.md](https://github.com/Steven147/InnoProject/blob/master/lsq/lsq_note.md)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## SSH远程连接\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- Linux/MacOS 作为终端\\n\",\r\n",
      "-    \"  - IP地址:`202.120.39.26:10151`,账号密码:`ipp20aitrojan`,`zft13917331612`\\n\",\r\n",
      "-    \"  - 连接命令:`ssh -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"  - 输入密码:`zft13917331612`\\n\",\r\n",
      "-    \"  - 登入成功！:`[ipp20aitrojan@localhost ~]$ .....`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 终端软件：[Introduction - Termius Documentation](https://docs.termius.com/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## jupyter notebook 远程连接\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[远程访问服务器Jupyter Notebook的两种方法 - 简书](https://www.jianshu.com/p/8fc3cd032d3c)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Running a notebook server — Jupyter Notebook 7.0.0.dev0 documentation](https://jupyter-notebook.readthedocs.io/en/latest/public_server.html#notebook-server-security)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 打开终端1：将本地端口号8888映射到服务器8889该过程只需要执行一次(通过`killall ssh`可以取消执行)\\n\",\r\n",
      "-    \"  - `ssh -N -f -L localhost:8888:localhost:8889 -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"  - 输入密码:`zft13917331612`\\n\",\r\n",
      "-    \"- 打开终端2\\n\",\r\n",
      "-    \"  - 使用SSH连接\\n\",\r\n",
      "-    \"    - 连接命令:`ssh -p 10151 ipp20aitrojan@202.120.39.26`\\n\",\r\n",
      "-    \"    - 输入密码:`zft13917331612`\\n\",\r\n",
      "-    \"  - 新建conda环境（python3），在新环境里下载jupyter notebook：`pip install notebook`\\n\",\r\n",
      "-    \"  - 配置jupyter环境（省略，因为已经配好了）\\n\",\r\n",
      "-    \"  - `jupyter notebook --no-browser --port=8889 --allow-root --certfile=mycert.pem --keyfile mykey.key`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 用网页打开链接[localhost](https://localhost:8888/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## Linux 基本使用\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [27个常用的 Linux 命令 - 简书](https://www.jianshu.com/p/0056d671ea6d)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [Ranger 用法总结 | 盼 の 欲](http://www.huangpan.net/posts/ji-ke/2019-08-21-ranger.html)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- `sudo su -`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## tf环境搭建\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"### 0 资源链接\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Anaconda Python/R Distribution - Free Download](https://www.anaconda.com/distribution/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Install TensorFlow 2](https://tensorflow.google.cn/install)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[tensorflow-tutorials](https://tensorflow.google.cn/tutorials)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"### 1 pip安装tf-gpu流程\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [Anaconda Python/R Distribution - Free Download](https://www.anaconda.com/distribution/)\\n\",\r\n",
      "-    \"  - Windows 下载安装包进行安装（过程略\\n\",\r\n",
      "-    \"  - Linux:\\n\",\r\n",
      "-    \"    - `$ wget https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh`\\n\",\r\n",
      "-    \"    - 运行shell\\n\",\r\n",
      "-    \"    - 将anaconda的bin目录加入PATH:`$ echo 'export PATH=\\\"~/anaconda3/bin:$PATH\\\"' >> ~/.bashrc`\\n\",\r\n",
      "-    \"    - 更新bashrc以立即生效:`$ source ~/.bashrc`\\n\",\r\n",
      "-    \"  - 检验:`conda --version`\\n\",\r\n",
      "-    \"  - [Conda常用命令整理\\\\_运维\\\\_Working. Playing.-CSDN博客](https://blog.csdn.net/menc15/article/details/71477949)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- （已经安装好了现成环境py36_tfgpu，拷贝为lsq_py36_tfgpu）`conda create --name lsq_py36_tfgpu --clone py36_tfgpu`\\n\",\r\n",
      "-    \"- `conda activate lsq_py36_tfgpu`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- [Install TensorFlow 2](https://tensorflow.google.cn/install)\\n\",\r\n",
      "-    \"  - 检验安装\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"    ```py\\n\",\r\n",
      "-    \"    import tensorflow as tf\\n\",\r\n",
      "-    \"    tf.test.is_gpu_available()\\n\",\r\n",
      "-    \"    ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"### 2 错误处理\\n\",\r\n",
      "-    \"\\n\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"markdown\",\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"source\": [\r\n",
      "-    \"# CITtrip项目：基于深度学习的网络异常行为检测\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"> 2.1 更新：《深度学习概览：算法，技术和应用》论文学习\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.2 更新：吴恩达-深度学习-bilibili\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.18 更新：《网络异常检测技术概述》论文学习 + tensorflow_keras学习\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.19 更新：《生成式对抗网络GAN的研究进展与展望_王坤峰》论文学习 + GAN模型损失函数理解 + tensorflow_keras学习2\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.20 更新：《基于深度卷积神经网络的网络流量分类方法》《卷积神经网络研究综述_周飞燕》论文学习 + tensorflow_keras学习3\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.21 更新：基于 tensorflow keras 的卷积神经网络实现 + tensorflow_gpu_for_mac install\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.22 更新：《基于深度置信网络的入侵检测模型》论文学习 + tensorflow keras 学习\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.23 更新：tensorflow keras\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.25 更新：《基于深度学习的网络流量分类及异常检测方法研究_王伟》 + 网络流量dataset组成 学习\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.26 更新：反向传播算法bp理解\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 2.29 更新：tensorflow keras 学习\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> 3.6 更新：本地程序运行 用tf.keras实现GAN网络\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 信息安全竞赛安排\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料一: 基于深度学习的网络异常检测技术研究_尹传龙\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 绪论\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   - 异常行为检测概述\\n\",\r\n",
      "-    \"     - 网络异常：网络设备异常、网络安全异常\\n\",\r\n",
      "-    \"     - 异常检测：设定正常行为轮廓“阈值”\\n\",\r\n",
      "-    \"       - 入侵检测：违背既定安全策略\\n\",\r\n",
      "-    \"       - 僵尸网络检测：受感染计算机构成的网络\\n\",\r\n",
      "-    \"   - 研究现状\\n\",\r\n",
      "-    \"     - 统计分析、数据挖掘、特征工程、\\n\",\r\n",
      "-    \"     - 机器学习\\n\",\r\n",
      "-    \"       - 贝叶斯网络\\n\",\r\n",
      "-    \"       - 遗传算法：模拟选择、交叉、变异等操作的搜索方法\\n\",\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-    \"       - 支持向量机：寻找最佳超平面区分不同类的样本\\n\",\r\n",
      "-    \"       - k最近邻\\n\",\r\n",
      "-    \"       - 决策树\\n\",\r\n",
      "-    \"       - 模糊逻辑\\n\",\r\n",
      "-    \"       - 人工神经网络\\n\",\r\n",
      "-    \"       - 深度学习\\n\",\r\n",
      "-    \"   - 数据集\\n\",\r\n",
      "-    \"     - 检测方法在实际中的检测性能效果高度依赖数据集\\n\",\r\n",
      "-    \"  \\n\",\r\n",
      "-    \"2. 全连接循环神经网络的入侵检测技术(略)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"3. 生成式对抗网络的入侵检测技术\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   - 生成式对抗网络：目的是学习真实数据样本的概率分布\\n\",\r\n",
      "-    \"     - 深度生成模型、引入对抗思想，解决样本较少问题\\n\",\r\n",
      "-    \"     - 由生成模型和判别模型组成\\n\",\r\n",
      "-    \"       - 生成模型为了尽可能模仿真实样本，学习捕捉真实数据样本的概率分布\\n\",\r\n",
      "-    \"       - 判别模型对真实样本和生成样本分类，等价于二分类模型\\n\",\r\n",
      "-    \"       - 双方对抗、优化，达到纳什平衡：生成\\n\",\r\n",
      "-    \"     - 问题：基于极大极小博弈机制的优化问题\\n\",\r\n",
      "-    \"       - 一方面：进化判别模型D，提升判别准确率\\n\",\r\n",
      "-    \"         - D(x) 将真实样本x判断为真实样本的概率，正确判断\\n\",\r\n",
      "-    \"         - D(G(z)) 将生成样本判断为真实样本的概率，错误判断\\n\",\r\n",
      "-    \"         - 目的：改善D，使D(x)增大、D(G(z))减小\\n\",\r\n",
      "-    \"       - 另一方面：进化生成模型G，尽量生成与真实数据相似的样本\\n\",\r\n",
      "-    \"         - G(z) 噪声z到生成样本空间的映射\\n\",\r\n",
      "-    \"         - 目的：改善G，使D(G(z))增大\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料二: A Survey on Deep Learning: Algorithms, Techniques, and Applications 深度学习概览：算法，技术和应用\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"> Deep learning uses multiple layers to represent the abstractions of data to build computational models.\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> The lack of core understanding renders these powerful methods as black-box machines that inhibit development at a fundamental level.\\n\",\r\n",
      "-    \">\\n\",\r\n",
      "-    \"> Moreover, deep learning has repeatedly been perceived as a silver bullet to all stumbling blocks in machine learning, which is far from the truth.\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- INTRODUCTION\\n\",\r\n",
      "-    \"  - 应用：多媒体概念检索，图像分类，视频推荐，社交网络分析，文本挖掘，**自然语言处理（NLP）**，视觉数据处理，语音和音频处理\\n\",\r\n",
      "-    \"  \\n\",\r\n",
      "-    \"    Deep learning, which has its roots from conventional neural networks, significantly outperforms its predecessors. It utilizes graph technologies with transformations among neurons to develop many-layered learning models.\\n\",\r\n",
      "-    \"    深度学习起源于传统的神经网络，其性能明显优于其前辈。它利用图技术以及神经元之间的转换来开发多层学习模型。\\n\",\r\n",
      "-    \"  - feature engineering 传统上，不良的数据表示通常会导致性能降低，因此，特征工程一直是重要的，且局限在特定领域，需要大量的人力\\n\",\r\n",
      "-    \"  - 相比之下，深度学习算法以自动方式执行特征提取，\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"    These algorithms include a layered architecture of data representation, where the high-level features can be extracted from the last layers of the networks while the  low-level features are extracted from the lower layers这些算法包括分层的数据表示架构，高层特征可以从网络的最后一层中提取，而底层要素从较低层提取\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"    The input is the scene information received from eyes, while the output is the classified objects.我们的大脑可以自动从不同场景中提取数据表示。 输入是从眼睛接收场景信息，而输出是分类对象。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"  - History\\n\",\r\n",
      "-    \"    - In 1980, neocogitron was intrduced, which inspired the convolutional neural network\\n\",\r\n",
      "-    \"    - Recurrent Neutal Networks were proposed in 1986\\n\",\r\n",
      "-    \"    - LeNet made the Deep Neural Networks\\n\",\r\n",
      "-    \"    - Deep Belief Networks (DBNs):Its main idea was to train a simple two-layer unsupervised model like Restricted Boltzmann Machines (RBMs), freeze all the parameters, stick a new layer on top, and train just the parameters for the new layer. 它的主要思想是训练一个简单的两层无监督模型，例如Restricted玻尔兹曼机器（RBM），冻结所有参数，在顶部粘贴新层并仅训练新层的参数。\\n\",\r\n",
      "-    \"    - deep learning now is one of the most efficient tools compared to other machinelearning algorithms with great performanc.与其他机器学习相比，深度学习现在是最有效的工具之一\\n\",\r\n",
      "-    \"    - ***从最初的Artificial Neural Networks(ANN)，到Deep Belief Networks DBN，Restricted Boltzmann Machines (RBMs)，Recurrent Neural Networks (RNNs)和Convolutional Neural Networks（CNN）***\\n\",\r\n",
      "-    \"    - 由于大量数据没有标签或带有噪音标签，因此一些研究更多地侧重于使用**无监督或半监督的**深度学习技术来提高训练模块的噪声鲁棒性。\\n\",\r\n",
      "-    \"    - cross-modality structure：由于当前大多数深度学习模型仅关注单一模式，因此导致对真实数据的表示有限。 研究人员现在更加关注跨模式结构\\n\",\r\n",
      "-    \"    - **Google AlphaGo**\\n\",\r\n",
      "-    \"  - Research Objectives and Outline 研究目的和概述\\n\",\r\n",
      "-    \"    - 介绍顶级论文，作者的经验，以及在深度神经网络研究和应用中的突破。\\n\",\r\n",
      "-    \"    - 在我们的调查中，提出了深度学习关键领域中的挑战和机遇，包括并行性，可伸缩性，功能和优化。为了解决上述问题，在不同的领域中引入了不同种类的深度网络，例如用于NLP的RNN和用于图像处理的CNN。 本文还介绍并比较了流行的深度学习工具，包括**Caffe，DeepLearning4j，TensorFlow，Theano和Torch**，以及每种深度学习工具中的优化技术。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- DEEP LEARNING NETWORKS：在第2节中，简要介绍了流行的深度学习网络。\\n\",\r\n",
      "-    \"  - 本节介绍的深度学习网络与其要点\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      | DL Networks | Descriptive Key Points                            |\\n\",\r\n",
      "-    \"      | ----------- | ------------------------------------------------- |\\n\",\r\n",
      "-    \"      | RvNN        | 使用树状结构。 NLP的首选                          |\\n\",\r\n",
      "-    \"      | RNN         | 适合顺序信息。首选用于NLP和语音处理               |\\n\",\r\n",
      "-    \"      | CNN         | 最初用于图像识别，扩展到NLP，语音处理和计算机视觉 |\\n\",\r\n",
      "-    \"      | DBN         | 无监督学习。定向连接                              |\\n\",\r\n",
      "-    \"      | DBM         | 无监督学习。RBM的复合模型。无向连接               |\\n\",\r\n",
      "-    \"      | GAN         | 无监督学习。博弈论框架                            |\\n\",\r\n",
      "-    \"      | VAE         | 无监督学习。概率图形模型                          |\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"  - Recursive Neural Network (RvNN)\\n\",\r\n",
      "-    \"  - Recurrent Neural Network (RNN)\\n\",\r\n",
      "-    \"  - Convolutional Neural Network (CNN)\\n\",\r\n",
      "-    \"  - Deep Generative Networks\\n\",\r\n",
      "-    \"- DEEP LEARNING TECHNIQUES AND FRAMEWORKS：第三部分讨论了深度学习中的几种算法，技术和框架。\\n\",\r\n",
      "-    \"  - Unsupervised and Transfer Learning 无监督和转移学习\\n\",\r\n",
      "-    \"  - Online Learning\\n\",\r\n",
      "-    \"  - Optimization Techniques in Deep Learning 深度学习中的优化技术\\n\",\r\n",
      "-    \"  - Deep Learning in Distributed Systems\\n\",\r\n",
      "-    \"  - Deep Lear ning Frameworks\\n\",\r\n",
      "-    \"- VARIOUS APPLICATIONS OF DEEP LEARNING：第4节中提供了许多深度学习的应用。\\n\",\r\n",
      "-    \"  - Natural Language Processing（略）\\n\",\r\n",
      "-    \"  - Visual Data Processing（略）\\n\",\r\n",
      "-    \"  - Speech and Audio Processing（略）\\n\",\r\n",
      "-    \"  - Other Applications（略）\\n\",\r\n",
      "-    \"- DEEP LEARNING CHALLENGES AND FUTURE DIRECTIONS：第5节指出了未来的挑战和潜在的研究方向。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料三：A survey of network anomaly detection techniques 网络异常检测技术概述\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 介绍\\n\",\r\n",
      "-    \"   1. 异常检测：数据挖掘任务 又称 utlier detection, novelty detection，deviation detection and exception mining.\\n\",\r\n",
      "-    \"   2. 异常：一个`与众不同`、疑似是`由不同的机制所产生`的观察结果\\n\",\r\n",
      "-    \"   3. 研究的挑战：异常检测技术普适性差（有线网-无线网）、噪声、缺乏labeled dataset\\n\",\r\n",
      "-    \"   4. 标准：计算复杂度、攻击检测优先级、输出\\n\",\r\n",
      "-    \"2. 前言\\n\",\r\n",
      "-    \"   1. 异常类型\\n\",\r\n",
      "-    \"      1. 点异常：\\n\",\r\n",
      "-    \"      2. 上下文异常：圣诞节交通量高在上下文中是正常的\\n\",\r\n",
      "-    \"      3. 集体异常：低心电图\\n\",\r\n",
      "-    \"   2. 异常检测技术的输出\\n\",\r\n",
      "-    \"      1. score\\n\",\r\n",
      "-    \"      2. label\\n\",\r\n",
      "-    \"   3. 网络攻击的类型\\n\",\r\n",
      "-    \"      1. 拒绝服务DoS攻击：server is flooded with numerous connection requests.\\n\",\r\n",
      "-    \"      2. 探针：探查攻击，对主机和网络攻击的第一步\\n\",\r\n",
      "-    \"      3. 用户到根U2R：获取super账户访问权限\\n\",\r\n",
      "-    \"      4. 远程用户R2U：\\n\",\r\n",
      "-    \"   4. 对异常的网络攻击进行分类  \\n\",\r\n",
      "-    \"      1. DoS：集体异常  \\n\",\r\n",
      "-    \"      2. 探测攻击：上下文异常\\n\",\r\n",
      "-    \"      3. 用户到根U2R，远程用户R2U：点异常\\n\",\r\n",
      "-    \"3. 基于分类的网络异常检测\\n\",\r\n",
      "-    \"   1. 支持向量机\\n\",\r\n",
      "-    \"      1. 寻找最优超平面，最大化分离\\n\",\r\n",
      "-    \"      2. `监督学习`！，\\n\",\r\n",
      "-    \"      3. 实例：正常活动下，有一组注册表项会被访问\\n\",\r\n",
      "-    \"   2. 贝叶斯网络\\n\",\r\n",
      "-    \"   3. 神经网络\\n\",\r\n",
      "-    \"   4. 基于规则：学习系统的正常行为\\n\",\r\n",
      "-    \"4. 统计异常检测\\n\",\r\n",
      "-    \"   1. 混合模型：数据由两个分布M，A其中一个生成，由A生成则是异常数据\\n\",\r\n",
      "-    \"   2. 信号处理技术\\n\",\r\n",
      "-    \"   3. 主成分分析：无假设、降维且不损失重要信息\\n\",\r\n",
      "-    \"5. 信息理论\\n\",\r\n",
      "-    \"   1. 信息熵、条件熵、相对熵\\n\",\r\n",
      "-    \"   2. 相关分析：网络流量间的非线性相关性\\n\",\r\n",
      "-    \"6. 聚类：无监督！\\n\",\r\n",
      "-    \"   1. 常规聚类：k-means聚类算法，分为正常，异常两类\\n\",\r\n",
      "-    \"7. 入侵检测数据集：\\n\",\r\n",
      "-    \"   1. DARPA / KDD数据集\\n\",\r\n",
      "-    \"   2. 当代网络攻击评估数据集：ADFA-LD12\\n\",\r\n",
      "-    \"8. 评估\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料四：生成式对抗网络GAN的研究进展与展望_王坤峰\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. GAN提出背景\\n\",\r\n",
      "-    \"   1. 生成式模型：通过生成方法（对数据分布的学习）得到的模型\\n\",\r\n",
      "-    \"      1. `人类理解数据角度`：对数据进行分布/参数假设-用真实数据进行训练/拟合-用学习到的分布/模型生成新样本：\\n\",\r\n",
      "-    \"         1. 最大似然估计\\n\",\r\n",
      "-    \"         2. **马尔科夫链**：效率较低\\n\",\r\n",
      "-    \"      2. `机器理解数据角度`：模型不直接拟合，而是从未明确假设的分布（初始数据集）中获取数据，对模型进行修正\\n\",\r\n",
      "-    \"   2. 神经网络：解决参数多、训练难的问题；\\n\",\r\n",
      "-    \"      1. 训练：反向传播算法\\n\",\r\n",
      "-    \"      2. 结构：自由灵活\\n\",\r\n",
      "-    \"      3. 建模能力：理论上能够逼近任意函数\\n\",\r\n",
      "-    \"   3. 对抗思想：AlphaGo 两个网络博弈\\n\",\r\n",
      "-    \"2. GAN的理论与实现模型\\n\",\r\n",
      "-    \"   1. 基本原理\\n\",\r\n",
      "-    \"      1. 生成器：学习真实的数据分布\\n\",\r\n",
      "-    \"         - G(z) 噪声z到生成样本空间的映射\\n\",\r\n",
      "-    \"         - 目的：改善G，使D(G(z))增大\\n\",\r\n",
      "-    \"      2. 判别器：判别数据是否源于生成器\\n\",\r\n",
      "-    \"         1. 判断是真实数据, 标记为 1（和D的取值不同！！\\n\",\r\n",
      "-    \"         2. 判断是生成器数据，标记为 0（和D的取值不同！！\\n\",\r\n",
      "-    \"         - D(x) 将真实样本x判断为真实样本的概率，正确判断\\n\",\r\n",
      "-    \"         - D(G(z)) 将生成样本判断为真实样本的概率，错误判断\\n\",\r\n",
      "-    \"         - 目的：改善D，使D(x)增大、D(G(z))减小\\n\",\r\n",
      "-    \"   2. `学习方法！！`：\\n\",\r\n",
      "-    \"      1. 最优化判别器：损失函数：对照图像理解\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"          > logistic回归 损失函数\\n\",\r\n",
      "-    \"          >\\n\",\r\n",
      "-    \"          > $J\\\\left( \\\\theta  \\\\right)=\\\\frac{1}{m}\\\\sum\\\\limits_{i=1}^{m}{{Cost}\\\\left( {h_\\\\theta}\\\\left( {x}^{\\\\left( i \\\\right)} \\\\right),{y}^{\\\\left( i \\\\right)} \\\\right)}$\\n\",\r\n",
      "-    \"          >\\n\",\r\n",
      "-    \"          > 为得到凸函数$J\\\\left( \\\\theta  \\\\right)$\\n\",\r\n",
      "-    \"          >\\n\",\r\n",
      "-    \"          > $J\\\\left( \\\\theta  \\\\right)=\\\\frac{1}{m}\\\\sum\\\\limits_{i=1}^{m}{[-{{y}^{(i)}}\\\\log \\\\left( {h_\\\\theta}\\\\left( {{x}^{(i)}} \\\\right) \\\\right)-\\\\left( 1-{{y}^{(i)}} \\\\right)\\\\log \\\\left( 1-{h_\\\\theta}\\\\left( {{x}^{(i)}} \\\\right) \\\\right)]}$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         - 训练判别器的损失函数：自变量有两个来源\\n\",\r\n",
      "-    \"           - ${D_\\\\theta}\\\\left( {x}\\\\right)$ 正确判断概率，目标为1，损失即与1的距离：$\\\\log \\\\left( {D_\\\\theta}\\\\left( {x} \\\\right) \\\\right)$\\n\",\r\n",
      "-    \"           - ${D_\\\\theta}\\\\left( g\\\\left(z \\\\right)\\\\right)$ 错误判断概率，目标为0，损失即与0的距离：$\\\\log \\\\left(1- {D_\\\\theta}\\\\left( {z} \\\\right) \\\\right)$\\n\",\r\n",
      "-    \"         - $J\\\\left( \\\\theta_D \\\\right)=-\\\\frac{1}{2}{E_1}\\\\log \\\\left( {D_\\\\theta}\\\\left( {x} \\\\right) \\\\right)- \\\\frac{1}{2}E_2 \\\\log \\\\left( 1-{D_\\\\theta }\\\\left( G\\\\left(z \\\\right)\\\\right) \\\\right)$\\n\",\r\n",
      "-    \"  \\n\",\r\n",
      "-    \"      2. 最优化生成器：损失函数，取判别器损失函数的相反数\\n\",\r\n",
      "-    \"         - $J\\\\left( \\\\theta_G \\\\right)=\\\\frac{1}{2}{E_1}\\\\log \\\\left( {D}\\\\left( {x} \\\\right) \\\\right)+ \\\\frac{1}{2}E_2 \\\\log \\\\left( 1-{D}\\\\left[ G_\\\\theta\\\\left(z \\\\right)\\\\right] \\\\right)$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      3. 过程：采用交替优化的方法：\\n\",\r\n",
      "-    \"         - $max_D min_G\\\\{\\\\ Loss\\\\left(\\\\theta_D \\\\theta_G \\\\right)={E_1}\\\\log \\\\left( {D_\\\\theta}\\\\left( {x} \\\\right) \\\\right)+ E_2 \\\\log \\\\left( 1-D_\\\\theta \\\\left[ G_\\\\theta\\\\left(z \\\\right)\\\\right] \\\\right)\\\\ \\\\}$\\n\",\r\n",
      "-    \"         - 先固定生成器 G, 优化判别器 D, 使得 D 的判别准确率最大化; \\n\",\r\n",
      "-    \"         - 然后固定判别器 D, 优化生成器 G, 使得 D 的判别准确率最小化\\n\",\r\n",
      "-    \"      4. GAN衍生模型\\n\",\r\n",
      "-    \"3. GAN的应用领域\\n\",\r\n",
      "-    \"   1. 视觉\\n\",\r\n",
      "-    \"   2. 语音语言\\n\",\r\n",
      "-    \"   3. 其他·\\n\",\r\n",
      "-    \"4. GAN的思考和展望\\n\",\r\n",
      "-    \"   1. 作为一种`生成式方法`, 有效解决了可建立自然性解释的数据的生成难题\\n\",\r\n",
      "-    \"   2. 将两个神经网络的对抗作为训练准则并且可以使用反向传播进行训练, 训练过程不需要效率较低的马尔科夫链方法, 也不需要做各种近似推理, 没有复杂的变分下界,\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料五：基于深度卷积神经网络的网络流量分类方法\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 引言\\n\",\r\n",
      "-    \"   1. 在网络流量分类领域的机器学习算法可以分为浅层学习和深度学习\\n\",\r\n",
      "-    \"   2. 浅层学习主要包括:支持向量机、决策树、 贝叶斯和 k-means\\n\",\r\n",
      "-    \"   3. 深度学习主要包括`**深度置信网络**`、`**卷积神经网络**`和`**递归神经网络**`等\\n\",\r\n",
      "-    \"   4. 基于离差标准化的卷积神经网络 min-max normalization convolutional neural network\\n\",\r\n",
      "-    \"2. 流量分类问题及描述\\n\",\r\n",
      "-    \"   1. 总体流程包括\\n\",\r\n",
      "-    \"      1. 网络数据的采集 现有的数据集 网络协议数据分析工具\\n\",\r\n",
      "-    \"      2. 带有准确背景信息数据集的生成\\n\",\r\n",
      "-    \"      3. 数据集的预处理，\\n\",\r\n",
      "-    \"      4. 流量特征的提取以及分类\\n\",\r\n",
      "-    \"   2. 采用卷积神经网络，构造合适的特征空间\\n\",\r\n",
      "-    \"      1. 对数据集进行数据预处理：将网络流量数据转化为灰度图片\\n\",\r\n",
      "-    \"      2. 将灰度图片作为卷积神经网络的输入数据进行学习\\n\",\r\n",
      "-    \"3. 基于改进卷积神经网络的网络流量分类方法\\n\",\r\n",
      "-    \"   1. 网络流量数据集的构建\\n\",\r\n",
      "-    \"      1. Moore 数据集\\n\",\r\n",
      "-    \"      2. 实际数据集\\n\",\r\n",
      "-    \"   2. 数据预处理\\n\",\r\n",
      "-    \"      1. 归一化：消除特征值的量纲，具有可比性\\n\",\r\n",
      "-    \"      2. 将构建好的矩阵中的每个元素作为一个像素点，矩阵中的值作为像素的灰度（白的程度\\n\",\r\n",
      "-    \"   3. 卷积神经网络\\n\",\r\n",
      "-    \"      1. 输入层、卷积层、池化层、全连接层、输出层\\n\",\r\n",
      "-    \"         1. 卷积层是卷积神经网络中最重要的一部分？\\n\",\r\n",
      "-    \"         2. 池化层也称为采样层？\\n\",\r\n",
      "-    \"         3. 全连接层通常位于卷积神经网络模型的最后位置，作用是计算网络的最终输出结果\\n\",\r\n",
      "-    \"   4. 训练过程\\n\",\r\n",
      "-    \"      1. 卷积层的前向传播形式为 激活函数为 ReLU 函数（去除负数\\n\",\r\n",
      "-    \"      2. 反向传播算法和BP神经网络类似，代价函数\\n\",\r\n",
      "-    \"   5. 改进的卷积神经网络结构\\n\",\r\n",
      "-    \"4. 实验测试与结果分析\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料六：《卷积神经网络研究综述_周飞燕.pdf》\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[大白话讲解卷积神经网络工作原理](https://www.bilibili.com/video/av35087157/?spm_id_from=333.788.videocard.0)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 引言\\n\",\r\n",
      "-    \"   1. 人工神经元网络 (Artificial Neural Network，ANN)是对生物神经网络的一种模拟和近似\\n\",\r\n",
      "-    \"   2. 反向传播网络 (Back Propagation Network，BP网络) **损失函数** => **通过训练自己得出卷积核**\\n\",\r\n",
      "-    \"   3. 逐层预训练 ”(layer-wise pre-training)\\n\",\r\n",
      "-    \"      1. 每次只无监督训练一层\\n\",\r\n",
      "-    \"      2. 将该层的训练结果作为其下一层的输入\\n\",\r\n",
      "-    \"      3. 有监督学习(BP算法)微调预训练好的网络\\n\",\r\n",
      "-    \"2. CNN概述\\n\",\r\n",
      "-    \"   1. 神经元：输入 权重 偏置 激励 输出\\n\",\r\n",
      "-    \"   2. 多层感知器：输入层、隐含层(一层或者多层)及输出层\\n\",\r\n",
      "-    \"   3. CNN：呈现出**图片结构**的数据\\n\",\r\n",
      "-    \"      1. 生物视觉感知\\n\",\r\n",
      "-    \"      2. 卷积层：通过`卷积核`提取出特征面，越高卷积层提取更高级的特征\\n\",\r\n",
      "-    \"      3. 池化层：降低特征面的分辨率\\n\",\r\n",
      "-    \"         1. 最大池化\\n\",\r\n",
      "-    \"         2. 平均池化\\n\",\r\n",
      "-    \"      4. 全连接层：用BP网络训练得到`权重`后，可导出分类结果\\n\",\r\n",
      "-    \"      5. `特征面`：根据实际应用进行设置\\n\",\r\n",
      "-    \"      6. 初始参数的确定（人为确定框架：找现成\\n\",\r\n",
      "-    \"         1. 卷积核数目、尺寸\\n\",\r\n",
      "-    \"         2. 池化大小、池化步长\\n\",\r\n",
      "-    \"         3. 全链接层神经元数量\\n\",\r\n",
      "-    \"3. 改进算法\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料七：基于深度置信网络的入侵检测模型\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[深度信念神经网络DBN最通俗易懂的教程](https://blog.csdn.net/u013631121/article/details/76794829?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Deep Learning（深度学习）学习笔记整理系列](https://blog.csdn.net/zouxy09/article/details/8775360)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 引言\\n\",\r\n",
      "-    \"2. 深度置信网络\\n\",\r\n",
      "-    \"   1. 由几个RBM和一层BP神经网络组成\\n\",\r\n",
      "-    \"   2. Restricting Boltzmann machine\\n\",\r\n",
      "-    \"      1. 一种两层随机神经网络\\n\",\r\n",
      "-    \"      2. 视觉层（v）\\n\",\r\n",
      "-    \"      3. 隐藏层（h）\\n\",\r\n",
      "-    \"      4. 能量函数\\n\",\r\n",
      "-    \"   3. BP神经网络\\n\",\r\n",
      "-    \"3. 入侵检测模型\\n\",\r\n",
      "-    \"4. 仿真与分析\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料八：基于深度学习的网络流量分类及异常检测方法研究_王伟\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 绪论\\n\",\r\n",
      "-    \"2. 基础知识和相关工作\\n\",\r\n",
      "-    \"   1. 网络流量分类方法\\n\",\r\n",
      "-    \"      1. 一般的网络流量分类\\n\",\r\n",
      "-    \"         1. 基于端口识别的分类方法\\n\",\r\n",
      "-    \"            1. 通过传输层的端口号识别 65535个 查表法\\n\",\r\n",
      "-    \"         2. 基于深层包检测的分类方法\\n\",\r\n",
      "-    \"            1. 检查整个数据包的内容\\n\",\r\n",
      "-    \"            2. 匹配固定的字符、字符串模式：也叫signature指纹\\n\",\r\n",
      "-    \"            3. 无法处理加密流量、未知流量\\n\",\r\n",
      "-    \"         3. 基于统计的分类方法\\n\",\r\n",
      "-    \"            1. 提取数据特征-机器学习\\n\",\r\n",
      "-    \"            2. 仅需特征数据，可用于加密流量\\n\",\r\n",
      "-    \"         4. 基于行为的分类方法\\n\",\r\n",
      "-    \"            1. 使用主机通信的行为信息：协议、端口、数量\\n\",\r\n",
      "-    \"      2. 恶意流量分类\\n\",\r\n",
      "-    \"      3. 加密流量分类\\n\",\r\n",
      "-    \"   2. 网络流量异常检测方法\\n\",\r\n",
      "-    \"   3. 深度学习\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 资料九：[读懂反向传播算法（bp算法）](https://www.jianshu.com/p/74bb815f612e)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"| 结构       | 神经元出    | 神经元入                                 | 神经元出 | 神经元入                                       |\\n\",\r\n",
      "-    \"| ---------- | ----------- | ---------------------------------------- | -------- | ---------------------------------------------- |\\n\",\r\n",
      "-    \"| 位置 层    | $l-1$       | $l$                                      | $l$      | $l+1$                                          |\\n\",\r\n",
      "-    \"| 位置 行    | $k$         | $j$                                      | $j$      | $i$                                            |\\n\",\r\n",
      "-    \"| 变量(向量) | $a_k^{l-1}$ | $a_k^{l-1}(A^{l-1})$                     | $a_j^{l}$ | $a_j^{l}(A^{l})$                               |\\n\",\r\n",
      "-    \"| 参数(向量) |             | $\\\\omega_{jk}^{l}(W_{j}^{l})$ , $b_j^{l}$ |          | $\\\\omega_{ij}^{l+1}(W_{i}^{l+1})$ , $b_i^{l+1}$ |\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"`正向运算过程：`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 神经元变量输入：$a_k^{l-1}$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 神经元参数输入：$\\\\omega_{jk}^{l}$，$b_j^{l}$\\n\",\r\n",
      "-    \"  > $k$取值范围为上一层神经元数，$j$对于单一神经元取值唯一\\n\",\r\n",
      "-    \"- 神经元处理：\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"  - $z_j^{l} = W_{j\\\\_}^{l}\\\\cdot A^{l-1}+b_j^{l}$\\n\",\r\n",
      "-    \"    > $a_k^{l-1}$,$\\\\omega_{jk}^{l}$ 排成$k$维列向量 $A^{l-1}$,$W_{j\\\\_}^{l}$\\n\",\r\n",
      "-    \"    >\\n\",\r\n",
      "-    \"    > 输入值对$l$层的任意神经元$j$都相同，故用$A^{l-1}$ 统一表示\\n\",\r\n",
      "-    \"  - $a_j^{l} = \\\\sigma(z_j^{l})$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 神经元输出：$a_j^{l} = \\\\sigma(z_j^{l})$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"`反向处理过程：`\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 损失函数：$C(A^{L})$\\n\",\r\n",
      "-    \"  > L为总层数\\n\",\r\n",
      "-    \"- 定义：$\\\\delta_{j}^{l} \\\\equiv \\\\frac{\\\\partial C}{\\\\partial z_j^{l}},\\\\Delta^{l} \\\\equiv \\\\frac{\\\\partial C}{\\\\partial Z^{l}}$\\n\",\r\n",
      "-    \"  > 对$l$层$j$个神经元而言，中间变量$\\\\delta_{j}^{l}$为**损失函数**对**未激活的输出值**的偏微分\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"- 计算：\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"  - 递推公式：$\\\\delta_{j}^{l} =\\\\frac{\\\\partial C}{\\\\partial Z^{l+1}}\\\\cdot \\\\frac{\\\\partial Z^{l+1}}{\\\\partial z_j^{l}} = \\\\Delta^{l+1} \\\\cdot W_{\\\\_j}^{l+1} \\\\cdot \\\\sigma^{,}(z_j^{l})$\\n\",\r\n",
      "-    \"    > $z_i^{l+1},\\\\delta_i^{l+1},\\\\omega_{ij}^{l+1}$ 排成$j$维列向量 $Z^{l+1},\\\\Delta^{l+1},W_{\\\\_j}^{l+1}$\\n\",\r\n",
      "-    \"    >\\n\",\r\n",
      "-    \"    > $W_{\\\\_j}^{l+1}$ 由所有从神经元$j$指出去的边的权重$\\\\omega_{ij}^{l+1}$排成\\n\",\r\n",
      "-    \"    >\\n\",\r\n",
      "-    \"    > 与上文由所有指向神经元$j$的边的权重$\\\\omega_{kj}^{l}$不同！！\\n\",\r\n",
      "-    \"  - 末值：$\\\\delta_{j}^{L} =\\\\frac{\\\\partial C}{\\\\partial A^{L}}\\\\cdot \\\\frac{\\\\partial A^{L}}{\\\\partial z_j^{L}}$\\n\",\r\n",
      "-    \"    > 特例为单输出值情况\\n\",\r\n",
      "-    \"    >\\n\",\r\n",
      "-    \"    > $\\\\frac{\\\\partial C}{\\\\partial a^{L}}$ 取决于损失函数形式，一般为$\\\\frac{1-y}{1-a^{L}}-\\\\frac{y}{a^{L}}$\\n\",\r\n",
      "-    \"    >\\n\",\r\n",
      "-    \"    > $\\\\frac{\\\\partial a^{L}}{\\\\partial z^{L}}$ 取决于激活函数形式，sigmoid时为$a^{L}\\\\cdot(1-a^{L})$\\n\",\r\n",
      "-    \"    >\\n\",\r\n",
      "-    \"    > $\\\\delta^{L} = a^{L} - y$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"  - 用法：\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"    - $\\\\frac{\\\\partial C}{\\\\partial \\\\omega_{jk}^{l}} = \\\\frac{\\\\partial C}{\\\\partial z_{j}^{l}} \\\\cdot \\\\frac{\\\\partial z_{j}^{l}}{\\\\partial \\\\omega_{jk}^{l}} = \\\\delta_{j}^{L} \\\\cdot a_{k}^{l-1}$\\n\",\r\n",
      "-    \"  \\n\",\r\n",
      "-    \"    - $\\\\frac{\\\\partial C}{\\\\partial b_{j}^{l}} = \\\\frac{\\\\partial C}{\\\\partial z_{j}^{l}} \\\\cdot \\\\frac{\\\\partial z_{j}^{l}}{\\\\partial b_{j}^{l}} = \\\\delta_{j}^{L}$\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"## 应用一：Tensorflow install\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Essential_documentation](https://tensorflow.google.cn/guide/)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. 安装\\n\",\r\n",
      "-    \"   1. 网址 [TensorFlow](https://tensorflow.google.cn/)\\n\",\r\n",
      "-    \"   2. 软件需求：python, pip, virtualenv\\\\conda\\n\",\r\n",
      "-    \"   3. 首次安装的版本可能并不契合网络资源所要求的tensorflow及其所需的python版本，因此可以使用conda创建虚拟环境选择合适的版本。\\n\",\r\n",
      "-    \"   4. tensorflow gpu 需要nvida显卡的支持，新款macbook搭载的是amd显卡，因此gpu版本安装问题无解\\n\",\r\n",
      "-    \"   5. 步骤\\n\",\r\n",
      "-    \"      - 下载anaconda_package（包含图形界面，对新手较友好） or [miniconda](https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/?C=M&O=A)\\n\",\r\n",
      "-    \"      - open anaconda powershell prompt\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ``` shell\\n\",\r\n",
      "-    \"      > conda --version\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      - 打开terminal，挂上SJTU_vpn\\n\",\r\n",
      "-    \"      - 通过conda创建虚拟环境并初始化python，激活刚刚创建的虚拟环境\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ``` shell\\n\",\r\n",
      "-    \"      > conda create -n tf pip python=3.7\\n\",\r\n",
      "-    \"      > conda activate tf\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      - 通过[清华源](https://mirror.tuna.tsinghua.edu.cn/help/pypi/)安装\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ``` shell\\n\",\r\n",
      "-    \"      (tf) > pip install -i https://pypi.tuna.tsinghua.edu.cn/simple tensorflow==2.1.0\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"2. 使用\\n\",\r\n",
      "-    \"   1. 步骤\\n\",\r\n",
      "-    \"      - 激活环境（也可以通过anaconda图形界面打开终端），进入python\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"        ``` shell\\n\",\r\n",
      "-    \"        > conda activate venv # 激活虚拟环境\\n\",\r\n",
      "-    \"        > python\\n\",\r\n",
      "-    \"        > conda deactivate #退出虚拟环境\\n\",\r\n",
      "-    \"        ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      - import tensorflow，导入tf.keras\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"          ```python\\n\",\r\n",
      "-    \"          import tensorflow as tf\\n\",\r\n",
      "-    \"          from tensorflow.keras import layers\\n\",\r\n",
      "-    \"          print(tf.__version__)\\n\",\r\n",
      "-    \"          print(tf.keras.__version__)\\n\",\r\n",
      "-    \"          ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"3. 问题修复\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   1. >\\\"Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\\\"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ```python\\n\",\r\n",
      "-    \"        >>> w=tf.Variable([[0.5,1.0]])\\n\",\r\n",
      "-    \"        2020-01-31 00:15:50.511182: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\\n\",\r\n",
      "-    \"        2020-01-31 00:15:50.527003: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7fc1dcc1a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\\n\",\r\n",
      "-    \"        2020-01-31 00:15:50.527021: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      问题所在：\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      [彻底解决“Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA”警告](https://blog.csdn.net/wlwlomo/article/details/82806118)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      [警告：Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA](https://blog.csdn.net/hq86937375/article/details/79696023)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      链接中提到，要换成支持cpu用AVX2编译的TensorFlow版本。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      如果您没有GPU并且希望尽可能多地利用CPU，那么如果您的CPU支持AVX，AVX2和FMA，则应该从针对CPU优化的源构建tensorflow。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      暂时解决方案：初学阶段重点在于理解原理，对于效率的提升不是重点，故忽略它（嘿嘿）\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      每次进入python环境时执行下列代码段，降低报警频率。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ```python\\n\",\r\n",
      "-    \"      import os\\n\",\r\n",
      "-    \"      os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   2. 版本问题\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ```python\\n\",\r\n",
      "-    \"      raise RuntimeError('The Session graph is empty.  Add operations to the '\\n\",\r\n",
      "-    \"      RuntimeError: The Session graph is empty.  Add operations to the graph before calling run().\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      暂时结论： tensorflow版本问题，函数使用方式产生了变更，一种方法是下载对应版本的tf，一种方法是改进使用代码。\\n\",\r\n",
      "-    \"\\n\"\r\n",
      "-   ]\r\n",
      "-  },\r\n",
      "-  {\r\n",
      "-   \"cell_type\": \"markdown\",\r\n",
      "-   \"metadata\": {},\r\n",
      "-   \"source\": [\r\n",
      "-    \"## 应用二：tensorflow.keras\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[tensorflow-tutorials](https://tensorflow.google.cn/tutorials)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"[Keras 快速搭建神经网络 (莫烦 Python 教程)](https://www.bilibili.com/video/av16910214)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"1. QuickStart\\n\",\r\n",
      "-    \"2. Keras\\n\",\r\n",
      "-    \"3. Load data\\n\",\r\n",
      "-    \"4. Estimator\\n\",\r\n",
      "-    \"5. Customization\\n\",\r\n",
      "-    \"6. Distributed training\\n\",\r\n",
      "-    \"7. Images\\n\",\r\n",
      "-    \"   1. CNN\\n\",\r\n",
      "-    \"      - [tf.keras.layers.Conv2D](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/Conv2D)\\n\",\r\n",
      "-    \"        - filters 输出空间future map的维数/层数/高度、过滤器（卷积核）的数量\\n\",\r\n",
      "-    \"        - kernel_size 卷积核大小\\n\",\r\n",
      "-    \"        - strides 步长\\n\",\r\n",
      "-    \"        - activation 激活函数\\n\",\r\n",
      "-    \"        - use_bias 是否使用偏置向量b，默认为true\\n\",\r\n",
      "-    \"        - 作为第一层需要额外提供，例如input_shape=(128, 128, 3) 用于中的128x128 RGB图片\\n\",\r\n",
      "-    \"      - [tf.keras.layers.MaxPool2D](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/MaxPool2D)\\n\",\r\n",
      "-    \"        - pool_size (2, 2)将在两个空间维度上将输入减半\\n\",\r\n",
      "-    \"        - strides 步长 默认为上值\\n\",\r\n",
      "-    \"      - 输出形状： 具有形状的4D张量： (samples, filters, new_rows, new_cols)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      ```py\\n\",\r\n",
      "-    \"      model = models.Sequential()\\n\",\r\n",
      "-    \"      model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\\n\",\r\n",
      "-    \"      #卷积核长与宽自己定，层数由输入图片层数决定，偏置bias b_i[1,1,1]，然后输出一张图 w_i[3,3,3]\\n\",\r\n",
      "-    \"      #输出次数自定 i[32]\\n\",\r\n",
      "-    \"      model.add(layers.MaxPooling2D((2, 2)))\\n\",\r\n",
      "-    \"      model.add(layers.Conv2D(64, (3, 3), activation='relu'))\\n\",\r\n",
      "-    \"      model.add(layers.MaxPooling2D((2, 2)))\\n\",\r\n",
      "-    \"      model.add(layers.Conv2D(64, (3, 3), activation='relu'))\\n\",\r\n",
      "-    \"      model.add(layers.Flatten()) # input 4*4*64 output 1024\\n\",\r\n",
      "-    \"      model.add(layers.Dense(64, activation='relu'))\\n\",\r\n",
      "-    \"      model.add(layers.Dense(10))\\n\",\r\n",
      "-    \"      model.summary()\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      Model: \\\"sequential_1\\\"\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      Layer (type)                 Output Shape              Param #\\n\",\r\n",
      "-    \"      =================================================================\\n\",\r\n",
      "-    \"      conv2d_3 (Conv2D)            (None, 30, 30, 32)        896 = (3*3*3+1)*32\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496 = (3*3*32+1)*64\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      conv2d_5 (Conv2D)            (None, 4, 4, 64)          36928 = (3*3*64+1)*64\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      flatten_1 (Flatten)          (None, 1024)              0\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      dense_2 (Dense)              (None, 64)                65600 = (1024+1)*64\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      dense_3 (Dense)              (None, 10)                650 = (64+1)*10\\n\",\r\n",
      "-    \"      =================================================================\\n\",\r\n",
      "-    \"      Total params: 122,570\\n\",\r\n",
      "-    \"      Trainable params: 122,570\\n\",\r\n",
      "-    \"      Non-trainable params: 0\\n\",\r\n",
      "-    \"      _________________________________________________________________\\n\",\r\n",
      "-    \"      ```\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"8. Text\\n\",\r\n",
      "-    \"9. Structure data\\n\",\r\n",
      "-    \"10. Generative\\n\",\r\n",
      "-    \"    1. DCGan\\n\",\r\n",
      "-    \"       1. [batch nomolization](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/BatchNormalization)\\n\",\r\n",
      "-    \"          - [【 深度学习李宏毅 】 Batch Normalization （中文）](https://www.bilibili.com/video/av16540598/)\\n\",\r\n",
      "-    \"          - normalization 意义：损失函数对范围大数值对应参数w更敏感，需要不同对学习速率/同化到相同范围\\n\",\r\n",
      "-    \"            - 后层的变化总是落后与前层变化\\n\",\r\n",
      "-    \"            - 保证每个layer输出相对固定，\\n\",\r\n",
      "-    \"            - 问题？但每个layer输出的mean和variant是不断变化的\\n\",\r\n",
      "-    \"          - batch normalization：可以调大rate加快训练速度，解决vanishing gradient\\n\",\r\n",
      "-    \"            - 可以在激活前后应用（推荐先normalization后activation：让值落在零的附近再激活效果较好）\\n\",\r\n",
      "-    \"            - batch 一串 把多个样本\\n\",\r\n",
      "-    \"            - 对每个layer的一串输出z求出z均值和z方差，然后根据均值和方差进行normalization\\n\",\r\n",
      "-    \"            - 如何bp？z均值和z方差也视为变量，而normalization后可以进行放缩和平移（常量）\\n\",\r\n",
      "-    \"            - training时的z均值和z方差在不断变化，在考虑正确率作为权重\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   ```py\\n\",\r\n",
      "-    \"   #generator\\n\",\r\n",
      "-    \"   def make_generator_model():\\n\",\r\n",
      "-    \"      model = tf.keras.Sequential()\\n\",\r\n",
      "-    \"      model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\\n\",\r\n",
      "-    \"      model.add(layers.BatchNormalization())\\n\",\r\n",
      "-    \"      model.add(layers.LeakyReLU())\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      model.add(layers.Reshape((7, 7, 256)))\\n\",\r\n",
      "-    \"      assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\\n\",\r\n",
      "-    \"      # b=0: not use bias\\n\",\r\n",
      "-    \"      assert model.output_shape == (None, 7, 7, 128)\\n\",\r\n",
      "-    \"      model.add(layers.BatchNormalization())\\n\",\r\n",
      "-    \"      model.add(layers.LeakyReLU())\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\\n\",\r\n",
      "-    \"      assert model.output_shape == (None, 14, 14, 64)\\n\",\r\n",
      "-    \"      model.add(layers.BatchNormalization())\\n\",\r\n",
      "-    \"      model.add(layers.LeakyReLU())\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\\n\",\r\n",
      "-    \"      assert model.output_shape == (None, 28, 28, 1)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      return model\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   generator = make_generator_model()\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   Layer (type)                 Output Shape              Param #\\n\",\r\n",
      "-    \"   =================================================================\\n\",\r\n",
      "-    \"   dense (Dense)                (None, 12544)             1254400 = 7*7*256*100\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   batch_normalization (BatchNo (None, 12544)             50176 = 12544*4????\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   leaky_re_lu (LeakyReLU)      (None, 12544)             0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   reshape (Reshape)            (None, 7, 7, 256)         0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200 = (5*5*256+0)*128\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   batch_normalization_1 (Batch (None, 7, 7, 128)         512 = 128*4\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800 = (5*5*128+0)*64\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   batch_normalization_2 (Batch (None, 14, 14, 64)        256 = 64*4\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1600 = (5*5*64+0)*1\\n\",\r\n",
      "-    \"   =================================================================\\n\",\r\n",
      "-    \"   Total params: 2,330,944\\n\",\r\n",
      "-    \"   Trainable params: 2,305,472\\n\",\r\n",
      "-    \"   Non-trainable params: 25,472\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   #discriminator\\n\",\r\n",
      "-    \"   def make_discriminator_model():\\n\",\r\n",
      "-    \"      model = tf.keras.Sequential()\\n\",\r\n",
      "-    \"      model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\\n\",\r\n",
      "-    \"                                       input_shape=[28, 28, 1]))\\n\",\r\n",
      "-    \"      model.add(layers.LeakyReLU())\\n\",\r\n",
      "-    \"      # [tf.keras.layers.LeakyReLU](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/LeakyReLU)\\n\",\r\n",
      "-    \"      model.add(layers.Dropout(0.3))\\n\",\r\n",
      "-    \"      # [tf.keras.layers.Dropout](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/Dropout) 将输入单元的一部分随机设置为0，这有助于防止过拟合。\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\\n\",\r\n",
      "-    \"      model.add(layers.LeakyReLU())\\n\",\r\n",
      "-    \"      model.add(layers.Dropout(0.3))\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      model.add(layers.Flatten())\\n\",\r\n",
      "-    \"      model.add(layers.Dense(1))\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      return model\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   discriminator = make_discriminator_model()\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   Layer (type)                 Output Shape              Param #\\n\",\r\n",
      "-    \"   =================================================================\\n\",\r\n",
      "-    \"   conv2d (Conv2D)              (None, 14, 14, 64)        1664 = (5*5*1+1)*64\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   dropout (Dropout)            (None, 14, 14, 64)        0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928 = (5*5*64+1)*128\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   dropout_1 (Dropout)          (None, 7, 7, 128)         0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   flatten (Flatten)            (None, 6272)              0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"   dense_1 (Dense)              (None, 1)                 6273\\n\",\r\n",
      "-    \"   =================================================================\\n\",\r\n",
      "-    \"   Total params: 212,865\\n\",\r\n",
      "-    \"   Trainable params: 212,865\\n\",\r\n",
      "-    \"   Non-trainable params: 0\\n\",\r\n",
      "-    \"   _________________________________________________________________\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   # Generator loss\\n\",\r\n",
      "-    \"   def generator_loss(fake_output):\\n\",\r\n",
      "-    \"      return cross_entropy(tf.ones_like(fake_output), fake_output)\\n\",\r\n",
      "-    \"   # Discriminator loss\\n\",\r\n",
      "-    \"   def discriminator_loss(real_output, fake_output):\\n\",\r\n",
      "-    \"      real_loss = cross_entropy(tf.ones_like(real_output), real_output)\\n\",\r\n",
      "-    \"      fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\\n\",\r\n",
      "-    \"      total_loss = real_loss + fake_loss\\n\",\r\n",
      "-    \"      return total_loss\\n\",\r\n",
      "-    \"   # discriminator and the generator optimizers ?????\\n\",\r\n",
      "-    \"   # [tf.keras.optimizers.Adam](https://tensorflow.google.cn/api_docs/python/tf/keras/optimizers/Adam?hl=en)\\n\",\r\n",
      "-    \"   generator_optimizer = tf.keras.optimizers.Adam(1e-4) #实现Adam算法的优化器。学习率\\n\",\r\n",
      "-    \"   discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   # training loop!!!\\n\",\r\n",
      "-    \"   def train_step(images):\\n\",\r\n",
      "-    \"      noise = tf.random.normal([BATCH_SIZE, noise_dim]) #根据batch大小生成随机数据\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\\n\",\r\n",
      "-    \"         generated_images = generator(noise, training=True) #生成器，输出图片数据(None, 28, 28, 1)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         real_output = discriminator(images, training=True) #判别器，输出判别数据(None, 1)\\n\",\r\n",
      "-    \"         fake_output = discriminator(generated_images, training=True) #判别器，输出判别数据(None, 1)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         gen_loss = generator_loss(fake_output)\\n\",\r\n",
      "-    \"         disc_loss = discriminator_loss(real_output, fake_output)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables) # 调用GradientTape.gradient方法，就会释放GradientTape拥有的资源\\n\",\r\n",
      "-    \"      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) #input:List of (gradient, variable) pairs\\n\",\r\n",
      "-    \"      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   def train(dataset, epochs):\\n\",\r\n",
      "-    \"      for epoch in range(epochs):\\n\",\r\n",
      "-    \"         start = time.time()\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         for image_batch in dataset: #BATCH_SIZE = 256\\n\",\r\n",
      "-    \"            train_step(image_batch) #image_batch.shape=(256, 28, 28, 1)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         # Produce images for the GIF as we go\\n\",\r\n",
      "-    \"         display.clear_output(wait=True)\\n\",\r\n",
      "-    \"         generate_and_save_images(generator,\\n\",\r\n",
      "-    \"                                 epoch + 1,\\n\",\r\n",
      "-    \"                                 seed)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         # Save the model every 15 epochs\\n\",\r\n",
      "-    \"         if (epoch + 1) % 15 == 0:\\n\",\r\n",
      "-    \"            checkpoint.save(file_prefix = checkpoint_prefix)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"         print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"      # Generate after the final epoch\\n\",\r\n",
      "-    \"      display.clear_output(wait=True)\\n\",\r\n",
      "-    \"      generate_and_save_images(generator,\\n\",\r\n",
      "-    \"                                 epochs,\\n\",\r\n",
      "-    \"                                 seed)\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   train(train_dataset, EPOCHS) #EPOCHS = 50 迭代五十次\\n\",\r\n",
      "-    \"\\n\",\r\n",
      "-    \"   ```\\n\"\r\n",
      "-   ]\r\n",
      "-  }\r\n",
      "- ],\r\n",
      "- \"metadata\": {\r\n",
      "-  \"kernelspec\": {\r\n",
      "-   \"display_name\": \"Python 3\",\r\n",
      "-   \"language\": \"python\",\r\n",
      "-   \"name\": \"python3\"\r\n",
      "-  },\r\n",
      "-  \"language_info\": {\r\n",
      "-   \"codemirror_mode\": {\r\n",
      "-    \"name\": \"ipython\",\r\n",
      "-    \"version\": 3\r\n",
      "-   },\r\n",
      "-   \"file_extension\": \".py\",\r\n",
      "-   \"mimetype\": \"text/x-python\",\r\n",
      "-   \"name\": \"python\",\r\n",
      "-   \"nbconvert_exporter\": \"python\",\r\n",
      "-   \"pygments_lexer\": \"ipython3\",\r\n",
      "-   \"version\": \"3.6.10\"\r\n",
      "-  }\r\n",
      "- },\r\n",
      "- \"nbformat\": 4,\r\n",
      "- \"nbformat_minor\": 4\r\n",
      "-}\r\n",
      "diff --git a/lsq/lsq_note.md b/lsq/lsq_note.md\r\n",
      "deleted file mode 100644\r\n",
      "index 794bd43..0000000\r\n",
      "--- a/lsq/lsq_note.md\r\n",
      "+++ /dev/null\r\n",
      "@@ -1,87 +0,0 @@\r\n",
      "-# 笔记 林绍钦\r\n",
      "-\r\n",
      "-[本文链接InnoProject/lsq\\_note.md](https://github.com/Steven147/InnoProject/blob/master/lsq/lsq_note.md)\r\n",
      "-\r\n",
      "-## 连接综述\r\n",
      "-\r\n",
      "-- termius\r\n",
      "-  - `sudo su -`\r\n",
      "-  - zft13917331612\r\n",
      "-  - `conda activate lsq_py36_tfgpu`\r\n",
      "-  - `jupyter notebook --no-browser --port=8889 --allow-root --certfile=mycert.pem --keyfile mykey.key`\r\n",
      "-- terminal\r\n",
      "-  - `ssh -N -f -L localhost:8888:localhost:8889 -p 10151 ipp20aitrojan@202.120.39.26`\r\n",
      "-  - zft13917331612\r\n",
      "-- [localhost](https://localhost:8888/)\r\n",
      "-\r\n",
      "-## SSH远程连接\r\n",
      "-\r\n",
      "-- Linux/MacOS 作为终端\r\n",
      "-  - IP地址:`202.120.39.26:10151`,账号密码:`ipp20aitrojan`,`zft13917331612`\r\n",
      "-  - 连接命令:`ssh -p 10151 ipp20aitrojan@202.120.39.26`\r\n",
      "-  - 输入密码:`zft13917331612`\r\n",
      "-  - 登入成功！:`[ipp20aitrojan@localhost ~]$ .....`\r\n",
      "-\r\n",
      "-- 终端软件：[Introduction - Termius Documentation](https://docs.termius.com/)\r\n",
      "-\r\n",
      "-## jupyter notebook 远程连接\r\n",
      "-\r\n",
      "-[远程访问服务器Jupyter Notebook的两种方法 - 简书](https://www.jianshu.com/p/8fc3cd032d3c)\r\n",
      "-\r\n",
      "-[Running a notebook server — Jupyter Notebook 7.0.0.dev0 documentation](https://jupyter-notebook.readthedocs.io/en/latest/public_server.html#notebook-server-security)\r\n",
      "-\r\n",
      "-- 打开终端1：将本地端口号8888映射到服务器8889该过程只需要执行一次(通过`killall ssh`可以取消执行)\r\n",
      "-  - `ssh -N -f -L localhost:8888:localhost:8889 -p 10151 ipp20aitrojan@202.120.39.26`\r\n",
      "-  - 输入密码:`zft13917331612`\r\n",
      "-- 打开终端2\r\n",
      "-  - 使用SSH连接\r\n",
      "-    - 连接命令:`ssh -p 10151 ipp20aitrojan@202.120.39.26`\r\n",
      "-    - 输入密码:`zft13917331612`\r\n",
      "-  - 新建conda环境（python3），在新环境里下载jupyter notebook：`pip install notebook`\r\n",
      "-  - 配置jupyter环境（省略，因为已经配好了）\r\n",
      "-  - `jupyter notebook --no-browser --port=8889 --allow-root --certfile=mycert.pem --keyfile mykey.key`\r\n",
      "-- 用网页打开链接[localhost](https://localhost:8888/)\r\n",
      "-\r\n",
      "-## Linux 基本使用\r\n",
      "-\r\n",
      "-- [27个常用的 Linux 命令 - 简书](https://www.jianshu.com/p/0056d671ea6d)\r\n",
      "-\r\n",
      "-- [Ranger 用法总结 | 盼 の 欲](http://www.huangpan.net/posts/ji-ke/2019-08-21-ranger.html)\r\n",
      "-\r\n",
      "-- `sudo su -`\r\n",
      "-\r\n",
      "-## tf环境搭建\r\n",
      "-\r\n",
      "-### 0 资源链接\r\n",
      "-\r\n",
      "-[Anaconda Python/R Distribution - Free Download](https://www.anaconda.com/distribution/)\r\n",
      "-\r\n",
      "-[Install TensorFlow 2](https://tensorflow.google.cn/install)\r\n",
      "-\r\n",
      "-[tensorflow-tutorials](https://tensorflow.google.cn/tutorials)\r\n",
      "-\r\n",
      "-### 1 pip安装tf-gpu流程\r\n",
      "-\r\n",
      "-- [Anaconda Python/R Distribution - Free Download](https://www.anaconda.com/distribution/)\r\n",
      "-  - Windows 下载安装包进行安装（过程略\r\n",
      "-  - Linux:\r\n",
      "-    - `$ wget https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh`\r\n",
      "-    - 运行shell\r\n",
      "-    - 将anaconda的bin目录加入PATH:`$ echo 'export PATH=\"~/anaconda3/bin:$PATH\"' >> ~/.bashrc`\r\n",
      "-    - 更新bashrc以立即生效:`$ source ~/.bashrc`\r\n",
      "-  - 检验:`conda --version`\r\n",
      "-  - [Conda常用命令整理\\_运维\\_Working. Playing.-CSDN博客](https://blog.csdn.net/menc15/article/details/71477949)\r\n",
      "-\r\n",
      "-- （已经安装好了现成环境py36_tfgpu，拷贝为lsq_py36_tfgpu）`conda create --name lsq_py36_tfgpu --clone py36_tfgpu`\r\n",
      "-- `conda activate lsq_py36_tfgpu`\r\n",
      "-\r\n",
      "-- [Install TensorFlow 2](https://tensorflow.google.cn/install)\r\n",
      "-  - 检验安装\r\n",
      "-\r\n",
      "-    ```py\r\n",
      "-    import tensorflow as tf\r\n",
      "-    tf.test.is_gpu_available()\r\n",
      "-    ```\r\n",
      "-\r\n",
      "-### 2 错误处理\r\n",
      "-\r\n"
     ]
    }
   ],
   "source": [
    "!git diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/innoproject\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: You ran 'git add' with neither '-A (--all)' or '--ignore-removal',\r\n",
      "whose behaviour will change in Git 2.0 with respect to paths you removed.\r\n",
      "Paths like 'lsq/.ipynb_checkpoints/README-checkpoint.ipynb' that are\r\n",
      "removed from your working tree are ignored with this version of Git.\r\n",
      "\r\n",
      "* 'git add --ignore-removal <pathspec>', which is the current default,\r\n",
      "  ignores paths you removed from your working tree.\r\n",
      "\r\n",
      "* 'git add --all <pathspec>' will let you also record the removals.\r\n",
      "\r\n",
      "Run 'git status' to check the paths you removed from your working tree.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[?47h\u001b[?1h\u001b=\u001b[1;24r\u001b[m\u001b[H\u001b[2J\u001b[24;1H\".git/COMMIT_EDITMSG\" 51L, 2142C\u001b[2;1H# Please enter the commit message for your changes. Lines starting\n",
      "# with '#' will be ignored, and an empty message aborts the commit.\n",
      "#\n",
      "# Committer: root <root@localhost.localdomain>\n",
      "#\n",
      "# On branch master\n",
      "#\n",
      "# Initial commit\n",
      "#\n",
      "# Changes to be committed:\n",
      "#   (use \"git rm --cached <file>...\" to unstage)\n",
      "#\n",
      "#\u001b[7Cnew file:   .ipynb_checkpoints/README-checkpoint.ipynb\n",
      "#\u001b[7Cnew file:   .ipynb_checkpoints/lsq_note-checkpoint.ipynb\n",
      "#\u001b[7Cnew file:   README.ipynb\n",
      "#\u001b[7Cnew file:   TABOR\n",
      "#\u001b[7Cnew file:   database_sqlite/.ipynb_checkpoints/database_sqlite-checkpoinn\u001b[19;1Ht.ipynb\n",
      "#\u001b[7Cnew file:   database_sqlite/.ipynb_checkpoints/search-checkpoint.ipynb\n",
      "#\u001b[7Cnew file:   database_sqlite/database_sqlite.ipynb\n",
      "#\u001b[7Cnew file:   database_sqlite/search.ipynb\n",
      "#\u001b[7Cnew file:   database_sqlite/test.db\u001b[1;1H\u001b[24;1HType  :quit<Enter>  to exit Vim\u001b[24;32H\u001b[K\u0007\u001b[1;1H"
     ]
    }
   ],
   "source": [
    "!git commit -m 'message'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authenticity of host 'github.com (13.250.177.223)' can't be established.\r\n",
      "RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.\r\n",
      "RSA key fingerprint is MD5:16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.\r\n",
      "Are you sure you want to continue connecting (yes/no)? "
     ]
    }
   ],
   "source": [
    "!git push origin master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 连接综述\n",
    "\n",
    "- termius\n",
    "  - `sudo su -`\n",
    "  - zft13917331612\n",
    "  - `conda activate lsq_py36_tfgpu`\n",
    "  - `jupyter notebook --no-browser --port=8889 --allow-root --certfile=mycert.pem --keyfile mykey.key`\n",
    "- terminal\n",
    "  - `ssh -N -f -L localhost:8888:localhost:8889 -p 10151 ipp20aitrojan@202.120.39.26`\n",
    "  - zft13917331612\n",
    "- [localhost](https://localhost:8888/)\n",
    "\n",
    "## SSH远程连接\n",
    "\n",
    "- Linux/MacOS 作为终端\n",
    "  - IP地址:`202.120.39.26:10151`,账号密码:`ipp20aitrojan`,`zft13917331612`\n",
    "  - 连接命令:`ssh -p 10151 ipp20aitrojan@202.120.39.26`\n",
    "  - 输入密码:`zft13917331612`\n",
    "  - 登入成功！:`[ipp20aitrojan@localhost ~]$ .....`\n",
    "\n",
    "- 终端软件：[Introduction - Termius Documentation](https://docs.termius.com/)\n",
    "\n",
    "## jupyter notebook 远程连接\n",
    "\n",
    "[远程访问服务器Jupyter Notebook的两种方法 - 简书](https://www.jianshu.com/p/8fc3cd032d3c)\n",
    "\n",
    "[Running a notebook server — Jupyter Notebook 7.0.0.dev0 documentation](https://jupyter-notebook.readthedocs.io/en/latest/public_server.html#notebook-server-security)\n",
    "\n",
    "- 打开终端1：将本地端口号8888映射到服务器8889该过程只需要执行一次(通过`killall ssh`可以取消执行)\n",
    "  - `ssh -N -f -L localhost:8888:localhost:8889 -p 10151 ipp20aitrojan@202.120.39.26`\n",
    "  - 输入密码:`zft13917331612`\n",
    "- 打开终端2\n",
    "  - 使用SSH连接\n",
    "    - 连接命令:`ssh -p 10151 ipp20aitrojan@202.120.39.26`\n",
    "    - 输入密码:`zft13917331612`\n",
    "  - 新建conda环境（python3），在新环境里下载jupyter notebook：`pip install notebook`\n",
    "  - 配置jupyter环境（省略，因为已经配好了）\n",
    "  - `jupyter notebook --no-browser --port=8889 --allow-root --certfile=mycert.pem --keyfile mykey.key`\n",
    "- 用网页打开链接[localhost](https://localhost:8888/)\n",
    "\n",
    "## Linux 基本使用\n",
    "\n",
    "- [27个常用的 Linux 命令 - 简书](https://www.jianshu.com/p/0056d671ea6d)\n",
    "\n",
    "- [Ranger 用法总结 | 盼 の 欲](http://www.huangpan.net/posts/ji-ke/2019-08-21-ranger.html)\n",
    "\n",
    "- `sudo su -`\n",
    "\n",
    "## tf环境搭建\n",
    "\n",
    "### 0 资源链接\n",
    "\n",
    "[Anaconda Python/R Distribution - Free Download](https://www.anaconda.com/distribution/)\n",
    "\n",
    "[Install TensorFlow 2](https://tensorflow.google.cn/install)\n",
    "\n",
    "[tensorflow-tutorials](https://tensorflow.google.cn/tutorials)\n",
    "\n",
    "### 1 pip安装tf-gpu流程\n",
    "\n",
    "- [Anaconda Python/R Distribution - Free Download](https://www.anaconda.com/distribution/)\n",
    "  - Windows 下载安装包进行安装（过程略\n",
    "  - Linux:\n",
    "    - `$ wget https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh`\n",
    "    - 运行shell\n",
    "    - 将anaconda的bin目录加入PATH:`$ echo 'export PATH=\"~/anaconda3/bin:$PATH\"' >> ~/.bashrc`\n",
    "    - 更新bashrc以立即生效:`$ source ~/.bashrc`\n",
    "  - 检验:`conda --version`\n",
    "  - [Conda常用命令整理\\_运维\\_Working. Playing.-CSDN博客](https://blog.csdn.net/menc15/article/details/71477949)\n",
    "\n",
    "- （已经安装好了现成环境py36_tfgpu，拷贝为lsq_py36_tfgpu）`conda create --name lsq_py36_tfgpu --clone py36_tfgpu`\n",
    "- `conda activate lsq_py36_tfgpu`\n",
    "\n",
    "- [Install TensorFlow 2](https://tensorflow.google.cn/install)\n",
    "  - 检验安装\n",
    "\n",
    "    ```py\n",
    "    import tensorflow as tf\n",
    "    tf.test.is_gpu_available()\n",
    "    ```\n",
    "\n",
    "### 2 错误处理\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 应用二：tensorflow.keras\n",
    "\n",
    "[tensorflow-tutorials](https://tensorflow.google.cn/tutorials)\n",
    "\n",
    "[Keras 快速搭建神经网络 (莫烦 Python 教程)](https://www.bilibili.com/video/av16910214)\n",
    "\n",
    "1. QuickStart\n",
    "2. Keras\n",
    "3. Load data\n",
    "4. Estimator\n",
    "5. Customization\n",
    "6. Distributed training\n",
    "7. Images\n",
    "   1. CNN\n",
    "      - [tf.keras.layers.Conv2D](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/Conv2D)\n",
    "        - filters 输出空间future map的维数/层数/高度、过滤器（卷积核）的数量\n",
    "        - kernel_size 卷积核大小\n",
    "        - strides 步长\n",
    "        - activation 激活函数\n",
    "        - use_bias 是否使用偏置向量b，默认为true\n",
    "        - 作为第一层需要额外提供，例如input_shape=(128, 128, 3) 用于中的128x128 RGB图片\n",
    "      - [tf.keras.layers.MaxPool2D](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/MaxPool2D)\n",
    "        - pool_size (2, 2)将在两个空间维度上将输入减半\n",
    "        - strides 步长 默认为上值\n",
    "      - 输出形状： 具有形状的4D张量： (samples, filters, new_rows, new_cols)\n",
    "\n",
    "      ```py\n",
    "      model = models.Sequential()\n",
    "      model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "      #卷积核长与宽自己定，层数由输入图片层数决定，偏置bias b_i[1,1,1]，然后输出一张图 w_i[3,3,3]\n",
    "      #输出次数自定 i[32]\n",
    "      model.add(layers.MaxPooling2D((2, 2)))\n",
    "      model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "      model.add(layers.MaxPooling2D((2, 2)))\n",
    "      model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "      model.add(layers.Flatten()) # input 4*4*64 output 1024\n",
    "      model.add(layers.Dense(64, activation='relu'))\n",
    "      model.add(layers.Dense(10))\n",
    "      model.summary()\n",
    "\n",
    "      Model: \"sequential_1\"\n",
    "      _________________________________________________________________\n",
    "      Layer (type)                 Output Shape              Param #\n",
    "      =================================================================\n",
    "      conv2d_3 (Conv2D)            (None, 30, 30, 32)        896 = (3*3*3+1)*32\n",
    "      _________________________________________________________________\n",
    "      max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0\n",
    "      _________________________________________________________________\n",
    "      conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496 = (3*3*32+1)*64\n",
    "      _________________________________________________________________\n",
    "      max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0\n",
    "      _________________________________________________________________\n",
    "      conv2d_5 (Conv2D)            (None, 4, 4, 64)          36928 = (3*3*64+1)*64\n",
    "      _________________________________________________________________\n",
    "      flatten_1 (Flatten)          (None, 1024)              0\n",
    "      _________________________________________________________________\n",
    "      dense_2 (Dense)              (None, 64)                65600 = (1024+1)*64\n",
    "      _________________________________________________________________\n",
    "      dense_3 (Dense)              (None, 10)                650 = (64+1)*10\n",
    "      =================================================================\n",
    "      Total params: 122,570\n",
    "      Trainable params: 122,570\n",
    "      Non-trainable params: 0\n",
    "      _________________________________________________________________\n",
    "      ```\n",
    "\n",
    "8. Text\n",
    "9. Structure data\n",
    "10. Generative\n",
    "    1. DCGan\n",
    "       1. [batch nomolization](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/BatchNormalization)\n",
    "          - [【 深度学习李宏毅 】 Batch Normalization （中文）](https://www.bilibili.com/video/av16540598/)\n",
    "          - normalization 意义：损失函数对范围大数值对应参数w更敏感，需要不同对学习速率/同化到相同范围\n",
    "            - 后层的变化总是落后与前层变化\n",
    "            - 保证每个layer输出相对固定，\n",
    "            - 问题？但每个layer输出的mean和variant是不断变化的\n",
    "          - batch normalization：可以调大rate加快训练速度，解决vanishing gradient\n",
    "            - 可以在激活前后应用（推荐先normalization后activation：让值落在零的附近再激活效果较好）\n",
    "            - batch 一串 把多个样本\n",
    "            - 对每个layer的一串输出z求出z均值和z方差，然后根据均值和方差进行normalization\n",
    "            - 如何bp？z均值和z方差也视为变量，而normalization后可以进行放缩和平移（常量）\n",
    "            - training时的z均值和z方差在不断变化，在考虑正确率作为权重\n",
    "\n",
    "   ```py\n",
    "   #generator\n",
    "   def make_generator_model():\n",
    "      model = tf.keras.Sequential()\n",
    "      model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "      model.add(layers.BatchNormalization())\n",
    "      model.add(layers.LeakyReLU())\n",
    "\n",
    "      model.add(layers.Reshape((7, 7, 256)))\n",
    "      assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "\n",
    "      model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "      # b=0: not use bias\n",
    "      assert model.output_shape == (None, 7, 7, 128)\n",
    "      model.add(layers.BatchNormalization())\n",
    "      model.add(layers.LeakyReLU())\n",
    "\n",
    "      model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "      assert model.output_shape == (None, 14, 14, 64)\n",
    "      model.add(layers.BatchNormalization())\n",
    "      model.add(layers.LeakyReLU())\n",
    "\n",
    "      model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "      assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "      return model\n",
    "\n",
    "   generator = make_generator_model()\n",
    "   _________________________________________________________________\n",
    "   Layer (type)                 Output Shape              Param #\n",
    "   =================================================================\n",
    "   dense (Dense)                (None, 12544)             1254400 = 7*7*256*100\n",
    "   _________________________________________________________________\n",
    "   batch_normalization (BatchNo (None, 12544)             50176 = 12544*4????\n",
    "   _________________________________________________________________\n",
    "   leaky_re_lu (LeakyReLU)      (None, 12544)             0\n",
    "   _________________________________________________________________\n",
    "   reshape (Reshape)            (None, 7, 7, 256)         0\n",
    "   _________________________________________________________________\n",
    "   conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200 = (5*5*256+0)*128\n",
    "   _________________________________________________________________\n",
    "   batch_normalization_1 (Batch (None, 7, 7, 128)         512 = 128*4\n",
    "   _________________________________________________________________\n",
    "   leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0\n",
    "   _________________________________________________________________\n",
    "   conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800 = (5*5*128+0)*64\n",
    "   _________________________________________________________________\n",
    "   batch_normalization_2 (Batch (None, 14, 14, 64)        256 = 64*4\n",
    "   _________________________________________________________________\n",
    "   leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0\n",
    "   _________________________________________________________________\n",
    "   conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1600 = (5*5*64+0)*1\n",
    "   =================================================================\n",
    "   Total params: 2,330,944\n",
    "   Trainable params: 2,305,472\n",
    "   Non-trainable params: 25,472\n",
    "   _________________________________________________________________\n",
    "\n",
    "\n",
    "\n",
    "   #discriminator\n",
    "   def make_discriminator_model():\n",
    "      model = tf.keras.Sequential()\n",
    "      model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                       input_shape=[28, 28, 1]))\n",
    "      model.add(layers.LeakyReLU())\n",
    "      # [tf.keras.layers.LeakyReLU](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/LeakyReLU)\n",
    "      model.add(layers.Dropout(0.3))\n",
    "      # [tf.keras.layers.Dropout](https://tensorflow.google.cn/api_docs/python/tf/keras/layers/Dropout) 将输入单元的一部分随机设置为0，这有助于防止过拟合。\n",
    "\n",
    "      model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "      model.add(layers.LeakyReLU())\n",
    "      model.add(layers.Dropout(0.3))\n",
    "\n",
    "      model.add(layers.Flatten())\n",
    "      model.add(layers.Dense(1))\n",
    "\n",
    "      return model\n",
    "\n",
    "   discriminator = make_discriminator_model()\n",
    "   _________________________________________________________________\n",
    "   Layer (type)                 Output Shape              Param #\n",
    "   =================================================================\n",
    "   conv2d (Conv2D)              (None, 14, 14, 64)        1664 = (5*5*1+1)*64\n",
    "   _________________________________________________________________\n",
    "   leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0\n",
    "   _________________________________________________________________\n",
    "   dropout (Dropout)            (None, 14, 14, 64)        0\n",
    "   _________________________________________________________________\n",
    "   conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928 = (5*5*64+1)*128\n",
    "   _________________________________________________________________\n",
    "   leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0\n",
    "   _________________________________________________________________\n",
    "   dropout_1 (Dropout)          (None, 7, 7, 128)         0\n",
    "   _________________________________________________________________\n",
    "   flatten (Flatten)            (None, 6272)              0\n",
    "   _________________________________________________________________\n",
    "   dense_1 (Dense)              (None, 1)                 6273\n",
    "   =================================================================\n",
    "   Total params: 212,865\n",
    "   Trainable params: 212,865\n",
    "   Non-trainable params: 0\n",
    "   _________________________________________________________________\n",
    "\n",
    "\n",
    "\n",
    "   # Generator loss\n",
    "   def generator_loss(fake_output):\n",
    "      return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "   # Discriminator loss\n",
    "   def discriminator_loss(real_output, fake_output):\n",
    "      real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "      fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "      total_loss = real_loss + fake_loss\n",
    "      return total_loss\n",
    "   # discriminator and the generator optimizers ?????\n",
    "   # [tf.keras.optimizers.Adam](https://tensorflow.google.cn/api_docs/python/tf/keras/optimizers/Adam?hl=en)\n",
    "   generator_optimizer = tf.keras.optimizers.Adam(1e-4) #实现Adam算法的优化器。学习率\n",
    "   discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "\n",
    "   # training loop!!!\n",
    "   def train_step(images):\n",
    "      noise = tf.random.normal([BATCH_SIZE, noise_dim]) #根据batch大小生成随机数据\n",
    "\n",
    "      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "         generated_images = generator(noise, training=True) #生成器，输出图片数据(None, 28, 28, 1)\n",
    "\n",
    "         real_output = discriminator(images, training=True) #判别器，输出判别数据(None, 1)\n",
    "         fake_output = discriminator(generated_images, training=True) #判别器，输出判别数据(None, 1)\n",
    "\n",
    "         gen_loss = generator_loss(fake_output)\n",
    "         disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables) # 调用GradientTape.gradient方法，就会释放GradientTape拥有的资源\n",
    "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) #input:List of (gradient, variable) pairs\n",
    "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "   def train(dataset, epochs):\n",
    "      for epoch in range(epochs):\n",
    "         start = time.time()\n",
    "\n",
    "         for image_batch in dataset: #BATCH_SIZE = 256\n",
    "            train_step(image_batch) #image_batch.shape=(256, 28, 28, 1)\n",
    "\n",
    "         # Produce images for the GIF as we go\n",
    "         display.clear_output(wait=True)\n",
    "         generate_and_save_images(generator,\n",
    "                                 epoch + 1,\n",
    "                                 seed)\n",
    "\n",
    "         # Save the model every 15 epochs\n",
    "         if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "         print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "      # Generate after the final epoch\n",
    "      display.clear_output(wait=True)\n",
    "      generate_and_save_images(generator,\n",
    "                                 epochs,\n",
    "                                 seed)\n",
    "\n",
    "   train(train_dataset, EPOCHS) #EPOCHS = 50 迭代五十次\n",
    "\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
