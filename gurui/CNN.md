# 卷积神经网络实现
卷积神经网络用以机器学习方法识别处理图像，处理过程可以与经典机器学习过程(回归问题、分类问题)相类比。

处理图像时input为像素点的灰度阵列，可以为$2$维或$3$维。
>$3$维实例：RGB检测

## Notations:
- $n^{(l)}$ :   第$l$层的输入维度
- $f^{(l)}$ :   第$l$层的卷积核维度
- $n^{(l)}_c$:  第$l$层输入的第三维度个数
- $p^{(l)}$:    处理第$l$层时，输入边缘向外 $padding$的长度
- $s^{(l)}$:    在第$l$层卷积运算的步长
- $(n^{(l)}_{c})^{'}$:  第$l$层输出的第三维度个数
- $b^{(l)}$:    第$l$层的偏置

## 具体实现过程
- Forward Propagation Algorithm
  - 实现要求
    - 人为选定卷积网络结构
      - 卷积层个数
      - 卷积核个数、卷积核维度
      - 激活函数
    - 初始化卷积参数
  - 说明
    - 第$l$层的输出经过加bias，加激活函数以后，输入到第$l+1$层，在这个过程中矩阵大小不变，于是有<center>
  $n^{(l+1)}=\lfloor \frac{n^{(l)}+2p^{(l)}-f^{(l)}}{s^{(l)}}+1 \rfloor$.<center>

    - $(n^{(l)}_c)^{'}$ 取决于第$l$层的卷积核的个数.
    - $n^{(l+1)}_c=(n^{(l)}_c)^{'}$. 这表示第$l+1$层输入的第三维度个数等于第$l$层输出的第三维度个数.
    - 类比经典机器学习神经网络，卷积运算就是线性组合的系数$w^{(l)}$, 加上一个偏置$b^{(l)}$。激活函数类似于sigmoid函数，得到的结果也类似与$a^{(l)}=g(z^{(l)})$.
    - 像素图未必是方阵，可以类似处理.
    - 卷积结束后将所得到的输出阵向量化处理，和输出向量连接，进行学习.

- BackPropagation Algorithm