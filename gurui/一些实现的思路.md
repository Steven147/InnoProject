突然闪现一个insight：

TABOR和BadNets实际上是相反的过程实现同一个效果：BadNets是已知触发然后训练模型把所有被污染的数据导向y_target1, 而TABOR是已知模型然后遍历所有trigger，找一个最佳的trigger使其与所有图叠加后导向y_target2（误差最小）。但是这里就有两个问题：

1. 训练trigger的时候是包含了20%被污染的元素的，对于这部分元素而言，TABOR进行的过程叠加的trigger与BadNets自带的trigger产生相互影响，这必然会影响trigger的准确性。
2. TABOR训练时默认y_target1=y_target2,但是这个未必成立。对于一个给定模型，如果原图叠加上BadNets的trigger就导向y_target1,如果叠加上TABOR的trigger就导向y_target2，那么如果同时叠加上这两个部分呢？经过对问题1的讨论我们知道，TABOR的trigger有一部分是在BadNets基础上训练得到的，这势必会导致如果不修改问题1，那么一个原图同时叠加上BadNets+TABOR的trigger就会导向y_target2。但是如果修复了第一个问题，那么将会导向哪里是未知的。这个特性可以用来做被污染数据集的判断与清除。即对于给定模型，已知了TABOR和BadNets训练的trigger和y_target1,y_target2，那么对每一张图片X而言，如果X没有被BadNets攻击，那么叠加上TABOR的trigger一定会导向y_target2。但是如果被BadNets攻击，那么叠加上TABOR的trigger就有可能导向y_target1,或者y_target2(置信度不高)。利用这个办法判断出哪些图片被污染，剔除以后重新训练就可以实现清除。