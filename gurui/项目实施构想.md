关于TABOR实现的一些思考：

1. 干净模型喂进去有没有trigger？会不会出bug？
2. 检测出来的trigger跟植入的trigger完全不同
3. 能不能在eval_snooper的时候找到已经被污染了的图然后检测
4. TABOR不能判断哪些图是被污染的，哪些图没有被污染

---

**项目目标**是希望能够将neural cleanse的内容和TABOR的工作合在一起，检测出trigger然后清除网络的错误问题，还原一个正确的网络。首先用gtsrb实验看一下能不能合起来，然后用多个数据集进行实验，测试模型的多数据集适用性。

baseline：基于gtsrb把neural cleanse做出来，前半部分用TABOR的结果替换（因为TABOR的结果更好）

1. 已经完成：
   1. TABOR的复现

能够提升的点：

1. 多数据集的模型适用性
2. 多攻击方式的检测适用性
   1. trojanNN对模型进行攻击
3. 有没有可能把trigger真实还原？（可能用到STRIP）

**下一步的工作：**

1. 读Neural Cleanse，BadNets
2. 整合跑Neural Cleanse（lsq）
3. 测试一下TABOR的bug（gr）
4. ppt

---

假设TABOR的应用场景，只给定模型（hdf5文件)，也很有可能知道模型的部分数据集，需要判断这个模型是否被污染，如果被污染的话需要去除污染。

TABOR的工作实际上是在已知hdf5文件+全部训练所用数据集+已知被污染+已知污染方式：BadNets+已知指向标签y_target的基础上做的，而真实的应用场景知道的信息很可能没有这么多。

所以考虑真实的应用场景，很可能需要对给定hdf5文件+部分数据集进行判断和神经元清除，这可以成为研究方向。

已知污染方式可以暂时定为最简单的badNets。

在TABOR的基础上做四步提升：

1. 检测出是否被以BadNets形式污染（STRIP或者统计学）
2. 如果被污染，检测出target_label。
3. 使用原训练集的一小部分进行训练，调节参数使训练效果优于同等训练量的TABOR
4. 使用Neural Cleanse做清除。